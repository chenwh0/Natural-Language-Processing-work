{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Please submit your solutions in either Assignment_302.ipynb or Assignment_302_alternative.ipynb—submission of both is not required.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Document Embeddings and Classification with Doc2Vec (10 points)\n",
    "\n",
    "**Background:**  \n",
    "This assignment investigates how Doc2Vec document embeddings perform for text classification tasks, using datasets from the Hugging Face Hub. You will implement and compare different Doc2Vec architectures (PV-DM and PV-DBOW), analyze document similarity patterns, and evaluate classification performance. The workflow follows the structure and code style shown in the attached practice notebooks.\n",
    "\n",
    "### Instructions and Point Breakdown\n",
    "\n",
    "**1. Dataset Preparation (2 points)**\n",
    "\n",
    "- Select any text classification dataset from Hugging Face Hub with at least 3 categories. Example datasets you can use (not limited to the following datasets):\n",
    "  - IMDb: https://huggingface.co/datasets/SetFit/imdb\n",
    "  - Amazon Polarity: https://huggingface.co/datasets/SetFit/amazon_polarity\n",
    "  - Yahoo Answers Topics: https://huggingface.co/datasets/sentence-transformers/yahoo-answers\n",
    "  - Banking77: https://huggingface.co/datasets/gtfintechlab/banking77 \n",
    "  - SMS Spam Collection: https://huggingface.co/datasets/ucirvine/sms_spam\n",
    "  - Hate Speech and Offensive Language: https://huggingface.co/datasets/Hate-speech-CNERG/hatexplain \n",
    "\n",
    "\n",
    "- Write code to:\n",
    "  - Load the dataset using `datasets.load_dataset()` from Hugging Face.\n",
    "  - Create TaggedDocument objects with unique identifiers for each document.\n",
    "  - Split into training and test sets if not already provided.\n",
    "- In 2–3 sentences, explain why TaggedDocument format is necessary for Doc2Vec training and how it differs from standard text preprocessing.\n",
    "\n",
    "**2. Doc2Vec Model Training (2 points)**\n",
    "\n",
    "- Train two Doc2Vec models using gensim:\n",
    "  - **PV-DM model:** Set `dm=1`, `vector_size=100`, `window=5`, `min_count=2`.\n",
    "  - **PV-DBOW model:** Set `dm=0`, `vector_size=100`, `window=5`, `min_count=2`.\n",
    "- Train both models for 20 epochs on the training documents.\n",
    "- Print the vocabulary size for each model and explain what the vector_size parameter represents.\n",
    "- Briefly discuss one advantage of PV-DM versus PV-DBOW architecture.\n",
    "\n",
    "**3. Document Similarity Analysis and Visualization (3 points)**\n",
    "\n",
    "- Select 10 documents from different categories in your test set.\n",
    "- Use both trained models to:\n",
    "  - Infer document vectors for these test documents.\n",
    "  - Compute pairwise cosine similarities between all document pairs.\n",
    "  - Create a similarity heatmap for each model showing which documents are most similar.\n",
    "- Compare similarity patterns between PV-DM and PV-DBOW models in a Markdown table.\n",
    "\n",
    "**4. Classification Performance Evaluation (2 points)**\n",
    "\n",
    "- Use the trained Doc2Vec models as feature extractors for classification:\n",
    "  - Extract document vectors for all training and test documents.\n",
    "  - Train a logistic regression classifier on the Doc2Vec features.\n",
    "  - Evaluate classification accuracy on the test set for both models.\n",
    "- Report and compare test accuracy for PV-DM and PV-DBOW approaches in a Markdown table.\n",
    "- In 2–3 sentences, interpret your findings: Which Doc2Vec variant performed better for your chosen dataset, and what might explain the difference?\n",
    "\n",
    "**5. Technical Reflection (1 point)**\n",
    "\n",
    "- In a Markdown cell, answer:\n",
    "  - How do Doc2Vec document embeddings compare to traditional bag-of-words approaches for text classification?\n",
    "  - Suggest one modification to improve the Doc2Vec models (e.g., different hyperparameters, ensemble methods, preprocessing).\n",
    "  - Name a real-world application where Doc2Vec would be particularly useful, and explain why document-level embeddings are advantageous for that task.\n",
    "\n",
    "### Submission Requirements\n",
    "\n",
    "- Jupyter Notebook containing:\n",
    "  - Clear, well-commented code for all sections\n",
    "  - Output cells showing similarity heatmaps and accuracy tables\n",
    "  - Reflection in Markdown cells\n",
    "- Use Python libraries: `datasets`, `gensim`, `scikit-learn`, `matplotlib`, `seaborn`, `numpy`\n",
    "\n",
    "#### Grading Rubric\n",
    "\n",
    "| Section                      | Points |\n",
    "|------------------------------|:------:|\n",
    "| Dataset preparation          |   2    |\n",
    "| Doc2Vec model training       |   2    |\n",
    "| Similarity analysis          |   3    |\n",
    "| Classification evaluation    |   2    |\n",
    "| Reflection quality           |   1    |\n",
    "| **Total**                    | **10** |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
