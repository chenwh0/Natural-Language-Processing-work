{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-tQ6BPQxUj_"
   },
   "source": [
    "# Assignment: Text Processing with Encoding Techniques (10 points)\n",
    "\n",
    "**Background:**\n",
    "Building on basic text processing concepts, this assignment explores three fundamental encoding techniques for NLP: one-hot encoding, bag-of-words (BoW), and TF-IDF. You'll implement these methods on text data and analyze their differences.\n",
    "\n",
    "**Note on generative AI use**: You are allowed to use any generative AI tool of your preference, as long as you are explicit about how and when/where you have used it to obtain your answers. You will be graded on the quality of your answers and your understanding of the concepts. NOT on the quality of your code. For example, you can use AI to come up with code solutions for each task, but a detailed explanation of your choices must be given. This includes but is not limited to: (i) what the code does, (ii) output samples if available, and (iii) your analysis. If your code is generated with AI, you should mention it and the name of the AI model used.\n",
    "\n",
    "## **Instructions and Point Breakdown**\n",
    "\n",
    "**1. Dataset Preparation (2 points)**\n",
    "\n",
    "- Select a text dataset (e.g., news headlines, product reviews, tweets)\n",
    "- Preprocess the text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation/stopwords\n",
    "    - Tokenizing sentences\n",
    "- Briefly justify your dataset choice and any particular challenges you faced.\n",
    "\n",
    "**2. Implement Encoding Techniques (4 points)**\n",
    "\n",
    "- **One-Hot Encoding (1.5 pts):**\n",
    "    - Build a vocabulary from unique tokens\n",
    "    - Convert sample sentences to one-hot vectors\n",
    "    - Use manual implementation (e.g., dictionary mapping)\n",
    "\n",
    "- **Bag-of-Words (1.5 pts):**\n",
    "    - Implement using `CountVectorizer`\n",
    "    - Show document-term matrix\n",
    "    - Compare with one-hot results\n",
    "\n",
    "- **TF-IDF (1 pt):**\n",
    "    - Generate TF-IDF vectors using `TfidfVectorizer`\n",
    "    - Explain TF vs. IDF components\n",
    "\n",
    "**3. Analysis and Visualization (2 points)**\n",
    "\n",
    "- Perform **one** of:\n",
    "    - Compare the top 5 features from each method\n",
    "    - Visualize word importance differences (e.g., bar chart)\n",
    "    - Compute cosine similarity between document vectors\n",
    "- Describe whichever analysis you perform\n",
    "\n",
    "**4. Technical Reflection (2 points)**\n",
    "\n",
    "- In a Markdown cell:\n",
    "    - Contrast use cases for each technique\n",
    "    - Explain how TF-IDF solves BoW limitations\n",
    "    - Discuss one challenge with sparse representations\n",
    "    - Suggest an AI prompt for handling large vocabularies\n",
    "\n",
    "\n",
    "## **Submission Requirements**\n",
    "\n",
    "- Jupyter Notebook containing:\n",
    "    - Code with comments (Sections 1-3)\n",
    "    - Outputs including matrices/visualizations\n",
    "    - Reflection (Section 4)\n",
    "- Use Python libraries: `sklearn`, `pandas`, `matplotlib`\n",
    "\n",
    "**Grading Rubric**\n",
    "\n",
    "\n",
    "| Section | Points |\n",
    "| :-- | :-- |\n",
    "| Dataset prep \\& preprocessing | 2 |\n",
    "| One-hot implementation | 1.5 |\n",
    "| BoW/TF-IDF implementation | 2.5 |\n",
    "| Analysis/visualization | 2 |\n",
    "| Quality of reflection | 2 |\n",
    "| **Total** | **10** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsqImdZhmNes"
   },
   "source": [
    "# *Sources used*\n",
    "* https://github.com/opengeos/geospatial-data-catalogs\n",
    "* https://www.geeksforgeeks.org/pandas/pandas-access-columns/\n",
    "* https://www.geeksforgeeks.org/python/difference-between-map-applymap-and-apply-methods-in-pandas/\n",
    "* https://www.geeksforgeeks.org/python/how-to-compare-two-dataframes-with-pandas-compare/\n",
    "* https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-sum/\n",
    "* https://www.geeksforgeeks.org/pandas/python-pandas-series-nlargest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO6RrmQHlIbS"
   },
   "source": [
    "# **Installs & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A6E_HY-um8Sr"
   },
   "outputs": [],
   "source": [
    "!pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLHwVD_7lMpr",
    "outputId": "ebab8c89-e3a6-4da0-e205-864e054d3805"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mch84/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "# Data preprocessing Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords # To remove stopwords in NLTK\n",
    "nltk_stopwords = set(stopwords.words(\"english\")) # Load English stopwords once for efficiency\n",
    "\n",
    "# Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer # To create one-hot encoding & bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # To create TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1wvgj7vk9j-"
   },
   "source": [
    "# **1. Data Preparation (2 points)**\n",
    "I chose this dataset because I wanted to learn more about how to do natural language processing on geospatial-related data. The dataset's source also contained concise instructions on how to retrieve the dataset. I didn't encounter particular challenges in this step, I mainly referred back to the previous 101 or 102 practice tutorial jupyter notebooks if I forgot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDoX02RMxT4u",
    "outputId": "9b0e6fc7-95f0-430b-aa45-ad5bd14c130f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Indian Remote Sensing satellites (IRS) are a series of Earth Observation satellites, built, launched and maintained by Indian Space Research Organisation. The IRS series provides many remote sensing services to India and international ground stations. With 5 m resolution and products covering areas up to 70 km x 70 km IRS LISS-IV mono data provide a cost effective solution for mapping tasks up to 1:25'000 scale.\n",
      "\n",
      "Preprocessed: indian remote sensing satellites irs series earth observation satellites built launched maintained indian space research organisation irs series provides many remote sensing services india international ground stations 5 resolution products covering areas 70 km x 70 km irs lissiv mono data provide cost effective solution mapping tasks 125000 scale\n"
     ]
    }
   ],
   "source": [
    "# Select text dataset\n",
    "url = 'https://github.com/opengeos/geospatial-data-catalogs/raw/master/nasa_cmr_catalog.tsv'\n",
    "dataframe = pd.read_csv(url, sep='\\t')\n",
    "title_description_dataframe = dataframe[[\"title\", \"description\"]]\n",
    "title_description_dataframe.head()\n",
    "\n",
    "# Preprocess text by removing punctuation, extra whitespace, and stopwords.\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower() # Lowercase all text.\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra whitespace\n",
    "    text_no_stopwords = [token for token in text.split(\" \") if token not in nltk_stopwords] # Store only the non-stopwords\n",
    "    text_no_stopwords = \" \".join(text_no_stopwords)\n",
    "    return text_no_stopwords\n",
    "\n",
    "preprocessed_dataframe = title_description_dataframe.copy() # Make a copy of original dataframe\n",
    "preprocessed_dataframe[\"description\"] = title_description_dataframe[\"description\"].map(preprocess_text) # Preprocess the copy's data\n",
    "\n",
    "# Tokenization & stopwords\n",
    "print(\"Original:\", title_description_dataframe[\"description\"][0])\n",
    "print(\"\\nPreprocessed:\", preprocessed_dataframe[\"description\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wln9iZRxWtzD"
   },
   "source": [
    "# **2. Implement Encoding Techniques (4 points)**\n",
    "\n",
    "*TF vs. IDF components*:\n",
    "*TF-IDF (Term Frequency-Inverse Document Frequency)*: Used weighting scheme to highlight important (rare) words in documents. Reduces impact of common words. Widely used for information retrieval & classification. Used in search engines.\n",
    ">**Formula for Term Frequency** = # of word’s occurrence in text/total # of words in text = probability\n",
    "\n",
    ">**Formula for Inverse Document Frequency** = idf(t) = log(1+N1+df(t))+1. Where N = total number of documents. df(t) = # of documents containing term t.\n",
    "\n",
    "> **Formula for TF-IDF** = tf(t,d) * idf(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "Xl4cQ9fETWSS",
    "outputId": "69db615b-fc47-4208-d528-ece75b7939a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000017966259</th>\n",
       "      <th>00344257</th>\n",
       "      <th>025</th>\n",
       "      <th>101109tgrs20172734070</th>\n",
       "      <th>11</th>\n",
       "      <th>113</th>\n",
       "      <th>125000</th>\n",
       "      <th>190pp207216</th>\n",
       "      <th>19781101</th>\n",
       "      <th>19822016</th>\n",
       "      <th>...</th>\n",
       "      <th>windsat</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>wã¼rzler</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yy</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>zircon</th>\n",
       "      <th>âimplications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000017966259  00344257  025  101109tgrs20172734070  11  113  125000  \\\n",
       "0             0         0    0                      0   0    0       1   \n",
       "1             0         0    0                      0   0    0       0   \n",
       "2             0         0    0                      0   0    0       0   \n",
       "3             0         0    0                      0   0    0       0   \n",
       "4             0         0    0                      0   0    0       0   \n",
       "\n",
       "   190pp207216  19781101  19822016  ...  windsat  within  work  wã¼rzler  \\\n",
       "0            0         0         0  ...        0       0     0         0   \n",
       "1            0         0         1  ...        0       1     0         1   \n",
       "2            0         0         0  ...        0       0     0         0   \n",
       "3            1         0         0  ...        0       1     0         0   \n",
       "4            0         0         0  ...        0       0     0         0   \n",
       "\n",
       "   year  yearly  yy  yyyymmdd  zircon  âimplications  \n",
       "0     0       0   0         0       0              0  \n",
       "1     0       0   0         0       0              0  \n",
       "2     0       1   0         0       0              0  \n",
       "3     0       0   0         0       0              1  \n",
       "4     0       0   0         0       0              0  \n",
       "\n",
       "[5 rows x 606 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bag of words dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000017966259</th>\n",
       "      <th>00344257</th>\n",
       "      <th>025</th>\n",
       "      <th>101109tgrs20172734070</th>\n",
       "      <th>11</th>\n",
       "      <th>113</th>\n",
       "      <th>125000</th>\n",
       "      <th>190pp207216</th>\n",
       "      <th>19781101</th>\n",
       "      <th>19822016</th>\n",
       "      <th>...</th>\n",
       "      <th>windsat</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>wã¼rzler</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yy</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>zircon</th>\n",
       "      <th>âimplications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000017966259  00344257  025  101109tgrs20172734070  11  113  125000  \\\n",
       "0             0         0    0                      0   0    0       1   \n",
       "1             0         0    0                      0   0    0       0   \n",
       "2             0         0    0                      0   0    0       0   \n",
       "3             0         0    0                      0   0    0       0   \n",
       "4             0         0    0                      0   0    0       0   \n",
       "\n",
       "   190pp207216  19781101  19822016  ...  windsat  within  work  wã¼rzler  \\\n",
       "0            0         0         0  ...        0       0     0         0   \n",
       "1            0         0         1  ...        0       1     0         1   \n",
       "2            0         0         0  ...        0       0     0         0   \n",
       "3            1         0         0  ...        0       1     0         0   \n",
       "4            0         0         0  ...        0       0     0         0   \n",
       "\n",
       "   year  yearly  yy  yyyymmdd  zircon  âimplications  \n",
       "0     0       0   0         0       0              0  \n",
       "1     0       0   0         0       0              0  \n",
       "2     0       1   0         0       0              0  \n",
       "3     0       0   0         0       0              1  \n",
       "4     0       0   0         0       0              0  \n",
       "\n",
       "[5 rows x 606 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TF-IDF matrix dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000017966259</th>\n",
       "      <th>00344257</th>\n",
       "      <th>025</th>\n",
       "      <th>101109tgrs20172734070</th>\n",
       "      <th>11</th>\n",
       "      <th>113</th>\n",
       "      <th>125000</th>\n",
       "      <th>190pp207216</th>\n",
       "      <th>19781101</th>\n",
       "      <th>19822016</th>\n",
       "      <th>...</th>\n",
       "      <th>windsat</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>wã¼rzler</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yy</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>zircon</th>\n",
       "      <th>âimplications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000017966259  00344257  025  101109tgrs20172734070   11  113    125000  \\\n",
       "0           0.0       0.0  0.0                    0.0  0.0  0.0  0.133695   \n",
       "1           0.0       0.0  0.0                    0.0  0.0  0.0  0.000000   \n",
       "2           0.0       0.0  0.0                    0.0  0.0  0.0  0.000000   \n",
       "3           0.0       0.0  0.0                    0.0  0.0  0.0  0.000000   \n",
       "4           0.0       0.0  0.0                    0.0  0.0  0.0  0.000000   \n",
       "\n",
       "   190pp207216  19781101  19822016  ...  windsat    within  work  wã¼rzler  \\\n",
       "0     0.000000       0.0  0.000000  ...      0.0  0.000000   0.0  0.000000   \n",
       "1     0.000000       0.0  0.049577  ...      0.0  0.042145   0.0  0.049577   \n",
       "2     0.000000       0.0  0.000000  ...      0.0  0.000000   0.0  0.000000   \n",
       "3     0.073856       0.0  0.000000  ...      0.0  0.062785   0.0  0.000000   \n",
       "4     0.000000       0.0  0.000000  ...      0.0  0.000000   0.0  0.000000   \n",
       "\n",
       "   year    yearly   yy  yyyymmdd  zircon  âimplications  \n",
       "0   0.0  0.000000  0.0       0.0     0.0       0.000000  \n",
       "1   0.0  0.000000  0.0       0.0     0.0       0.000000  \n",
       "2   0.0  0.056143  0.0       0.0     0.0       0.000000  \n",
       "3   0.0  0.000000  0.0       0.0     0.0       0.073856  \n",
       "4   0.0  0.000000  0.0       0.0     0.0       0.000000  \n",
       "\n",
       "[5 rows x 606 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract unique words to form vocabulary for each text\n",
    "descriptions = preprocessed_dataframe[\"description\"].tolist()[:10] # Get list of all description row values\n",
    "vectorizer_vocab = CountVectorizer()\n",
    "vectorizer_vocab.fit(descriptions)\n",
    "vocab = vectorizer_vocab.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding\n",
    "vectorizer = CountVectorizer(vocabulary=vocab, binary=True)\n",
    "onehot = vectorizer.transform(descriptions)\n",
    "onehot_dataframe = pd.DataFrame(onehot.toarray(),\n",
    "                      columns=vocab) # Display frequency of each word in the given text through Pandas DataFrame\n",
    "print(\"one-hot encoding dataframe:\")\n",
    "display(onehot_dataframe.head())\n",
    "\n",
    "# Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(descriptions) # Fit vectorizer to list of text to build vocabulary\n",
    "bag_of_words = vectorizer.transform(descriptions) # Transform list of text into a bag-of-words matrix\n",
    "bow_dataframe = pd.DataFrame(bag_of_words.toarray(),\n",
    "                      columns=vocab) # Display frequency of each word in the given text through Pandas DataFrame\n",
    "print(\"\\n\\nBag of words dataframe:\")\n",
    "display(bow_dataframe.head())\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(descriptions) # Fit vectorizer to list of text to build vocabulary\n",
    "tfidf_matrix = vectorizer.transform(descriptions) # Transform the documents into a TF-IDF-weighted term-document matrix\n",
    "tfidf_dataframe = pd.DataFrame(tfidf_matrix.toarray(),\n",
    "                      columns=vocab) # Display frequency of each word in the given text through Pandas DataFrame\n",
    "print(\"\\n\\nTF-IDF matrix dataframe:\")\n",
    "display(tfidf_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "7AjpzbvFrIx4",
    "outputId": "36869882-247e-4eb5-ba4e-b7997df0b517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Onehot = self. BoW = other. NaN = same values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">2017</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2018</th>\n",
       "      <th colspan=\"2\" halign=\"left\">70</th>\n",
       "      <th colspan=\"2\" halign=\"left\">absorption</th>\n",
       "      <th colspan=\"2\" halign=\"left\">aerosol</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">transantarctic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">upb</th>\n",
       "      <th colspan=\"2\" halign=\"left\">used</th>\n",
       "      <th colspan=\"2\" halign=\"left\">wagner</th>\n",
       "      <th colspan=\"2\" halign=\"left\">zircon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>...</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  2017       2018         70       absorption       aerosol        ...  \\\n",
       "  self other self other self other       self other    self other  ...   \n",
       "0  NaN   NaN  NaN   NaN  1.0   2.0        NaN   NaN     NaN   NaN  ...   \n",
       "1  NaN   NaN  1.0   2.0  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "2  NaN   NaN  NaN   NaN  NaN   NaN        1.0   6.0     NaN   NaN  ...   \n",
       "3  NaN   NaN  NaN   NaN  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "4  NaN   NaN  NaN   NaN  NaN   NaN        NaN   NaN     1.0   3.0  ...   \n",
       "5  1.0   3.0  NaN   NaN  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "6  NaN   NaN  NaN   NaN  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "7  NaN   NaN  NaN   NaN  NaN   NaN        1.0   3.0     NaN   NaN  ...   \n",
       "8  NaN   NaN  NaN   NaN  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "9  NaN   NaN  NaN   NaN  NaN   NaN        NaN   NaN     NaN   NaN  ...   \n",
       "\n",
       "  transantarctic        upb       used       wagner       zircon        \n",
       "            self other self other self other   self other   self other  \n",
       "0            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "1            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "2            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "3            NaN   NaN  NaN   NaN  1.0   2.0    NaN   NaN    NaN   NaN  \n",
       "4            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "5            NaN   NaN  NaN   NaN  NaN   NaN    1.0   3.0    NaN   NaN  \n",
       "6            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "7            NaN   NaN  NaN   NaN  NaN   NaN    NaN   NaN    NaN   NaN  \n",
       "8            1.0   2.0  1.0   3.0  NaN   NaN    NaN   NaN    1.0   4.0  \n",
       "9            1.0   2.0  1.0   3.0  NaN   NaN    NaN   NaN    1.0   4.0  \n",
       "\n",
       "[10 rows x 258 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare one-hot encoding with bag of words encoding\n",
    "print(\"\\nOnehot = self. BoW = other. NaN = same values\")\n",
    "display(onehot_dataframe.compare(bow_dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxj2E8rSrJKv"
   },
   "source": [
    "# **3. Analysis and Visualization (2 points)**\n",
    "\n",
    "I choose to compare the top 5 features (words) from each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_gxvb7fXRxVW",
    "outputId": "c5912e88-c4ee-42cb-b73e-1f5fa651e621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 WORDS FROM EACH METHOD\n",
      "\n",
      "One hot encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>also</th>\n",
       "      <th>esa</th>\n",
       "      <th>products</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  also  esa  products  project\n",
       "0     1     0    0         1        0\n",
       "1     1     1    1         1        1\n",
       "2     1     1    1         1        1\n",
       "3     1     0    1         0        1\n",
       "4     1     0    1         1        1\n",
       "5     1     1    1         1        1\n",
       "6     1     1    1         1        1\n",
       "7     1     1    1         1        1\n",
       "8     0     1    0         0        0\n",
       "9     0     1    0         0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bag of words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>dataset</th>\n",
       "      <th>samples</th>\n",
       "      <th>also</th>\n",
       "      <th>cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  dataset  samples  also  cloud\n",
       "0     1        0        0     0      0\n",
       "1     5        9        0     2     13\n",
       "2     5        4        0     2      0\n",
       "3     4        0        0     0      0\n",
       "4     1        1        0     0      0\n",
       "5     3        2        0     2      0\n",
       "6     3        4        0     2      0\n",
       "7     4        2        0     3      0\n",
       "8     0        0        7     1      0\n",
       "9     0        0        7     1      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TF-IDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>samples</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cloud</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.110039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.644499</td>\n",
       "      <td>0.024167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.157849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.170128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data   samples   dataset     cloud  products\n",
       "0  0.059349  0.000000  0.000000  0.000000  0.065171\n",
       "1  0.110039  0.000000  0.239528  0.644499  0.024167\n",
       "2  0.146586  0.000000  0.141815  0.000000  0.032193\n",
       "3  0.131143  0.000000  0.000000  0.000000  0.000000\n",
       "4  0.073153  0.000000  0.088465  0.000000  0.240988\n",
       "5  0.071781  0.000000  0.057871  0.000000  0.052549\n",
       "6  0.157849  0.000000  0.254519  0.000000  0.115556\n",
       "7  0.170128  0.000000  0.102869  0.000000  0.093409\n",
       "8  0.000000  0.445671  0.000000  0.000000  0.000000\n",
       "9  0.000000  0.445671  0.000000  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# five largest values in first 10 rows word columns across 3 dataframes\n",
    "def display_top_n_features(dataframe, n=5):\n",
    "    column_counts = dataframe.sum(axis=0) # sum the totals in each column (rows with more 1s/larger values will have larger sums)\n",
    "    top_5_columns = column_counts.nlargest(n).index # Get indicies of top 5 columns with max sums\n",
    "    display(dataframe[top_5_columns])\n",
    "print(\"TOP 5 WORDS FROM EACH METHOD\\n\")\n",
    "print(\"One hot encoding:\")\n",
    "display_top_n_features(onehot_dataframe)\n",
    "\n",
    "print(\"\\n\\nBag of words:\")\n",
    "display_top_n_features(bow_dataframe)\n",
    "\n",
    "print(\"\\n\\nTF-IDF:\")\n",
    "display_top_n_features(tfidf_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IVO_nIPrMUR"
   },
   "source": [
    "# **4. Technical Reflection (2 points)**\n",
    "- Contrast use cases for each technique -\n",
    "  * *one-hot encoding reveals* that the top 5 \"important\" words were: \"data\", \"also\", \"esa\", \"products\", \"project\". These words shows up the most consistently across the 10 documents (descriptions).\n",
    "  * *bag of words matrix* reveals that the top 5 \"important\" words were: \"data\", \"dataset\", \"samples\", \"also\", \"cloud\". These are the highest reoccurring words in the 10 documents. For words such as \"sample\" and \"cloud\" they did not show up very consistently across all 10 documents but there were enough reoccurrences in a mere few documents (descriptions) for them to become one of the top 5 words in BoW.\n",
    "  * TF-IDF matrix reveals that the top 5 \"important\" words were: \"data\", \"samples\", \"dataset\", \"cloud\", \"products\". These were words that either were frequently showing up or words that rarely showed up across all documents but when they did show up, they showed up a lot.\n",
    "- Explain how TF-IDF solves BoW limitations - BoW scores were high for stopwords that occur frequently but weren't important. TF-IDF resolved this by assigning lower scores to words that occurred frequently across ALL documents (descriptions). This allows words like \"also\" to not have a higher score than say, \"cloud\".\n",
    "\n",
    "- Discuss one challenge with sparse representations - One challenge with sparse representations is it's limited capturing of context. This means that these representation can't capture the true meaning behind words and thus the usages of these encodings are severely limited compared to under text representations.\n",
    "- Suggest an AI prompt for handling large vocabularies - \"How can I prevent my computer from running out of RAM when calculating the TF-IDF, BoW, or one-hot encodings from a corpus has a large vocabulary?\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
