{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO01hwQnzxo03+56cH/mH/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenwh0/Natural-Language-Processing-work/blob/main/module5/HowTokenizationAndEmbeddingsWorksInsideLLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploration and Analysis of Tokenization and Embeddings in Modern LLMs**\n",
        "\n",
        "**Background:**  \n",
        "This lab tested how multiple real tokenizers operate, dissect how their output impacts the resulting embeddings, and analyze why these choices matter for both accuracy and efficiency in language tasks.\n",
        "\n",
        "# *Sources/References*\n",
        "\n",
        "* Academic Data source: https://pubmed.ncbi.nlm.nih.gov/18270555/\n",
        "\n",
        "### Instructions & Deliverables\n",
        "\n",
        "#### 1. **Tokenization Deep Dive (2 points)**\n",
        "\n",
        "- Select *five diverse sentences*:  \n",
        "  - Two with formal academic language  \n",
        "  - One with slang or social media language  \n",
        "  - One with an emoji  \n",
        "  - One with code/math notation  \n",
        "- For each sentence, tokenize with **three different pretrained tokenizers** (choose from e.g. `bert-base-uncased`, `gpt2`, `microsoft/Phi-3-mini-4k-instruct`, `google/flan-t5-small`, etc.).\n",
        "- Display for each:\n",
        "  - The original text\n",
        "  - The sequence of tokens and their decoded forms (subwords)\n",
        "  - The token IDs\n",
        "\n",
        "#### 2. **Cross-Tokenizer Comparison (2 points)**\n",
        "\n",
        "- Place your results in a **comparison table**:\n",
        "  - For each sentence and tokenizer, show:  \n",
        "    - Number of tokens  \n",
        "    - How words or special features (names/emoji/code) are split\n",
        "    - Presence of [UNK] or unknown tokens\n",
        "- In a *markdown cell*, answer:  \n",
        "  - Which tokenization schemes are more robust to slang, emojis, and code?  \n",
        "  - Which produce the longest and shortest sequences? Why?\n",
        "\n",
        "#### 3. **Token Embedding Visualization (3 points)**\n",
        "\n",
        "- Pick one sentence and one tokenizer from your previous results.\n",
        "- Use the tokenizer‚Äôs pretrained embedding layer (from its associated model) to produce the embedding vector for each token in the sentence.\n",
        "- Use PCA or t-SNE to project the token embeddings to 2D and create a **scatter plot**:\n",
        "  - Each point should be labeled with the decoded token.\n",
        "  - Color points differently for subwords, whole words, and special tokens.\n",
        "- Comment on the geometry: Do related words/subwords cluster? Are special tokens outliers?\n",
        "\n",
        "#### 4. **Prompt Engineering & Model Output (2 points)**\n",
        "\n",
        "- Take two tokenized prompts that yielded notably different token splits across tokenizers (e.g. one with code/math and one with informal language).\n",
        "- For each:\n",
        "  - Use two *different* language models (‚Äúmatching‚Äù the tokenizer used) to generate text completions.\n",
        "  - In a short table, report:\n",
        "    - Length (in tokens and characters) of the generated output\n",
        "    - Are any [UNK] tokens, empty outputs, or odd/non-conversational results observed?\n",
        "- Discuss how the tokenizer choice might affect downstream output quality and efficiency.\n",
        "\n",
        "#### 5. **Reflection (1 point)**\n",
        "\n",
        "- In a paragraph (markdown), summarize:\n",
        "  - How does the choice of tokenizer and embedding scheme affect which kinds of input a model can ‚Äúunderstand‚Äù?\n",
        "  - Why must LLM practitioners consider both the *efficiency* (sequence length) and the *semantic coverage* (handling unknowns, subwords, emoji) of each tokenizer?\n",
        "\n",
        "**Submission**:  \n",
        "Produce a Jupyter notebook with clearly separated code and markdown cells for each section. All code must run under Python and Hugging Face Transformers. Include all required tables, plots, and discussion.\n",
        "\n",
        "**Grading Rubric:**\n",
        "\n",
        "| Section                           | Points |\n",
        "|:-----------------------------------|:------:|\n",
        "| Tokenization Deep Dive             | 2      |\n",
        "| Cross-Tokenizer Comparison Table & Analysis | 2 |\n",
        "| Embedding Visualization            | 3      |\n",
        "| Prompt Engineering & Model Output  | 2      |\n",
        "| Reflection                        | 1      |\n",
        "| **Total**                         | **10** |"
      ],
      "metadata": {
        "id": "8fvEQv8KLBxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Installs & Imports*"
      ],
      "metadata": {
        "id": "d5koIsx7eZPV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agsFcEwFLBMW"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing libraries\n",
        "import pandas\n",
        "\n",
        "# Tokenizer library\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Tokenization Deep Dives**\n",
        "\n",
        "a. Selected *5 diverse sentences*\n",
        "  - 2 with formal academic language  \n",
        "  - 1 with slang or social media language  \n",
        "  - 1 with an emoji  \n",
        "  - 1 with code/math notation  \n",
        "\n",
        "b. Tokenized each sentence with **3 different pretrained tokenizers** (`bert-base-uncased`, `gpt2`, `microsoft/Phi-3-mini-4k-instruct`).\n",
        "\n",
        "c. Displayed for each sentence:\n",
        "  - The original text\n",
        "  - The sequence of tokens and their decoded forms (subwords)\n",
        "  - The token IDs"
      ],
      "metadata": {
        "id": "kd9WUdFHedv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"New methodologies and prototype systems for dynamically incorporating automatic feature extraction, visual selection, and knowledge-rich semantics for content-based image database management and retrieval are needed to assist image analysts.\",\n",
        "    \"GeoIRIS can be best described by its architecture as shown in Fig. 1. There are six modules: feature extraction (FE), indexing structures (IS), semantic framework (SF), GeoName server (GS), fusion and ranking (FR), and retrieval visualization (RV).\",\n",
        "    \"If I get one more L I'm gonna yeet my controller out a window no cap\",\n",
        "    \"One will need a üñ•Ô∏è first to make a üåè application.\",\n",
        "    \"To ensure features are rotationally insensitive, we order each bin, i ‚àà [1, F], from W+y and W‚àíy, such that S[i] = max {W +yi , W ‚àíyi } and S[i + F] = min {W +yi , W ‚àíyi }\"\n",
        "]"
      ],
      "metadata": {
        "id": "gekLjDOrA2UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of RGB color codes for highlighting tokens in the output\n",
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "    # Load the specified tokenizer from Hugging Face\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    # Tokenize the input sentence and get token IDs\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    print(\"Original text:\", sentence)\n",
        "    tokenized_prompt = []\n",
        "    # Iterate over each token ID and print the decoded token with colored background\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        text = tokenizer.decode(t)\n",
        "        print(\n",
        "            # ANSI escape code for colored background using RGB values from colors_list\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            text +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )\n",
        "        #tokenized_prompt.append((text, t))\n",
        "\n",
        "    print(\"\\nToken IDs:\", token_ids)\n",
        "    print()\n",
        "    return token_ids"
      ],
      "metadata": {
        "id": "V5fTDqPPNezo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_split(tokenizer_name, texts):\n",
        "    tokenized_prompts = []\n",
        "    for text in texts:\n",
        "        token_ids = show_tokens(text, tokenizer_name)\n",
        "        tokenized_prompts.append(token_ids)\n",
        "    return tokenized_prompts"
      ],
      "metadata": {
        "id": "WZO8XoMLOiGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenized_prompts = tokenizer_split(\"bert-base-uncased\", texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBdYqt6RP3i0",
        "outputId": "69757b69-2910-4263-c564-cf9881200f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: New methodologies and prototype systems for dynamically incorporating automatic feature extraction, visual selection, and knowledge-rich semantics for content-based image database management and retrieval are needed to assist image analysts.\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mnew\u001b[0m \u001b[0;30;48;2;141;160;203mmethod\u001b[0m \u001b[0;30;48;2;231;138;195m##ologies\u001b[0m \u001b[0;30;48;2;166;216;84mand\u001b[0m \u001b[0;30;48;2;255;217;47mprototype\u001b[0m \u001b[0;30;48;2;102;194;165msystems\u001b[0m \u001b[0;30;48;2;252;141;98mfor\u001b[0m \u001b[0;30;48;2;141;160;203mdynamic\u001b[0m \u001b[0;30;48;2;231;138;195m##ally\u001b[0m \u001b[0;30;48;2;166;216;84mincorporating\u001b[0m \u001b[0;30;48;2;255;217;47mautomatic\u001b[0m \u001b[0;30;48;2;102;194;165mfeature\u001b[0m \u001b[0;30;48;2;252;141;98mextraction\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mvisual\u001b[0m \u001b[0;30;48;2;166;216;84mselection\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165mand\u001b[0m \u001b[0;30;48;2;252;141;98mknowledge\u001b[0m \u001b[0;30;48;2;141;160;203m-\u001b[0m \u001b[0;30;48;2;231;138;195mrich\u001b[0m \u001b[0;30;48;2;166;216;84msemantics\u001b[0m \u001b[0;30;48;2;255;217;47mfor\u001b[0m \u001b[0;30;48;2;102;194;165mcontent\u001b[0m \u001b[0;30;48;2;252;141;98m-\u001b[0m \u001b[0;30;48;2;141;160;203mbased\u001b[0m \u001b[0;30;48;2;231;138;195mimage\u001b[0m \u001b[0;30;48;2;166;216;84mdatabase\u001b[0m \u001b[0;30;48;2;255;217;47mmanagement\u001b[0m \u001b[0;30;48;2;102;194;165mand\u001b[0m \u001b[0;30;48;2;252;141;98mretrieval\u001b[0m \u001b[0;30;48;2;141;160;203mare\u001b[0m \u001b[0;30;48;2;231;138;195mneeded\u001b[0m \u001b[0;30;48;2;166;216;84mto\u001b[0m \u001b[0;30;48;2;255;217;47massist\u001b[0m \u001b[0;30;48;2;102;194;165mimage\u001b[0m \u001b[0;30;48;2;252;141;98manalysts\u001b[0m \u001b[0;30;48;2;141;160;203m.\u001b[0m \u001b[0;30;48;2;231;138;195m[SEP]\u001b[0m \n",
            "Token IDs: [101, 2047, 4118, 20792, 1998, 8773, 3001, 2005, 8790, 3973, 13543, 6882, 3444, 14676, 1010, 5107, 4989, 1010, 1998, 3716, 1011, 4138, 28081, 2005, 4180, 1011, 2241, 3746, 7809, 2968, 1998, 26384, 2024, 2734, 2000, 6509, 3746, 18288, 1012, 102]\n",
            "\n",
            "Original text: GeoIRIS can be best described by its architecture as shown in Fig. 1. There are six modules: feature extraction (FE), indexing structures (IS), semantic framework (SF), GeoName server (GS), fusion and ranking (FR), and retrieval visualization (RV).\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mgeo\u001b[0m \u001b[0;30;48;2;141;160;203m##iri\u001b[0m \u001b[0;30;48;2;231;138;195m##s\u001b[0m \u001b[0;30;48;2;166;216;84mcan\u001b[0m \u001b[0;30;48;2;255;217;47mbe\u001b[0m \u001b[0;30;48;2;102;194;165mbest\u001b[0m \u001b[0;30;48;2;252;141;98mdescribed\u001b[0m \u001b[0;30;48;2;141;160;203mby\u001b[0m \u001b[0;30;48;2;231;138;195mits\u001b[0m \u001b[0;30;48;2;166;216;84marchitecture\u001b[0m \u001b[0;30;48;2;255;217;47mas\u001b[0m \u001b[0;30;48;2;102;194;165mshown\u001b[0m \u001b[0;30;48;2;252;141;98min\u001b[0m \u001b[0;30;48;2;141;160;203mfig\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m1\u001b[0m \u001b[0;30;48;2;255;217;47m.\u001b[0m \u001b[0;30;48;2;102;194;165mthere\u001b[0m \u001b[0;30;48;2;252;141;98mare\u001b[0m \u001b[0;30;48;2;141;160;203msix\u001b[0m \u001b[0;30;48;2;231;138;195mmodules\u001b[0m \u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47mfeature\u001b[0m \u001b[0;30;48;2;102;194;165mextraction\u001b[0m \u001b[0;30;48;2;252;141;98m(\u001b[0m \u001b[0;30;48;2;141;160;203mfe\u001b[0m \u001b[0;30;48;2;231;138;195m)\u001b[0m \u001b[0;30;48;2;166;216;84m,\u001b[0m \u001b[0;30;48;2;255;217;47mindex\u001b[0m \u001b[0;30;48;2;102;194;165m##ing\u001b[0m \u001b[0;30;48;2;252;141;98mstructures\u001b[0m \u001b[0;30;48;2;141;160;203m(\u001b[0m \u001b[0;30;48;2;231;138;195mis\u001b[0m \u001b[0;30;48;2;166;216;84m)\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165msemantic\u001b[0m \u001b[0;30;48;2;252;141;98mframework\u001b[0m \u001b[0;30;48;2;141;160;203m(\u001b[0m \u001b[0;30;48;2;231;138;195msf\u001b[0m \u001b[0;30;48;2;166;216;84m)\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165mgeo\u001b[0m \u001b[0;30;48;2;252;141;98m##name\u001b[0m \u001b[0;30;48;2;141;160;203mserver\u001b[0m \u001b[0;30;48;2;231;138;195m(\u001b[0m \u001b[0;30;48;2;166;216;84mgs\u001b[0m \u001b[0;30;48;2;255;217;47m)\u001b[0m \u001b[0;30;48;2;102;194;165m,\u001b[0m \u001b[0;30;48;2;252;141;98mfusion\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195mranking\u001b[0m \u001b[0;30;48;2;166;216;84m(\u001b[0m \u001b[0;30;48;2;255;217;47mfr\u001b[0m \u001b[0;30;48;2;102;194;165m)\u001b[0m \u001b[0;30;48;2;252;141;98m,\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195mretrieval\u001b[0m \u001b[0;30;48;2;166;216;84mvisual\u001b[0m \u001b[0;30;48;2;255;217;47m##ization\u001b[0m \u001b[0;30;48;2;102;194;165m(\u001b[0m \u001b[0;30;48;2;252;141;98mrv\u001b[0m \u001b[0;30;48;2;141;160;203m)\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m[SEP]\u001b[0m \n",
            "Token IDs: [101, 20248, 15735, 2015, 2064, 2022, 2190, 2649, 2011, 2049, 4294, 2004, 3491, 1999, 20965, 1012, 1015, 1012, 2045, 2024, 2416, 14184, 1024, 3444, 14676, 1006, 10768, 1007, 1010, 5950, 2075, 5090, 1006, 2003, 1007, 1010, 21641, 7705, 1006, 16420, 1007, 1010, 20248, 18442, 8241, 1006, 28177, 1007, 1010, 10077, 1998, 5464, 1006, 10424, 1007, 1010, 1998, 26384, 5107, 3989, 1006, 27634, 1007, 1012, 102]\n",
            "\n",
            "Original text: If I get one more L I'm gonna yeet my controller out a window no cap\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mif\u001b[0m \u001b[0;30;48;2;141;160;203mi\u001b[0m \u001b[0;30;48;2;231;138;195mget\u001b[0m \u001b[0;30;48;2;166;216;84mone\u001b[0m \u001b[0;30;48;2;255;217;47mmore\u001b[0m \u001b[0;30;48;2;102;194;165ml\u001b[0m \u001b[0;30;48;2;252;141;98mi\u001b[0m \u001b[0;30;48;2;141;160;203m'\u001b[0m \u001b[0;30;48;2;231;138;195mm\u001b[0m \u001b[0;30;48;2;166;216;84mgonna\u001b[0m \u001b[0;30;48;2;255;217;47mye\u001b[0m \u001b[0;30;48;2;102;194;165m##et\u001b[0m \u001b[0;30;48;2;252;141;98mmy\u001b[0m \u001b[0;30;48;2;141;160;203mcontroller\u001b[0m \u001b[0;30;48;2;231;138;195mout\u001b[0m \u001b[0;30;48;2;166;216;84ma\u001b[0m \u001b[0;30;48;2;255;217;47mwindow\u001b[0m \u001b[0;30;48;2;102;194;165mno\u001b[0m \u001b[0;30;48;2;252;141;98mcap\u001b[0m \u001b[0;30;48;2;141;160;203m[SEP]\u001b[0m \n",
            "Token IDs: [101, 2065, 1045, 2131, 2028, 2062, 1048, 1045, 1005, 1049, 6069, 6300, 3388, 2026, 11486, 2041, 1037, 3332, 2053, 6178, 102]\n",
            "\n",
            "Original text: One will need a üñ•Ô∏è first to make a üåè application.\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mone\u001b[0m \u001b[0;30;48;2;141;160;203mwill\u001b[0m \u001b[0;30;48;2;231;138;195mneed\u001b[0m \u001b[0;30;48;2;166;216;84ma\u001b[0m \u001b[0;30;48;2;255;217;47m[UNK]\u001b[0m \u001b[0;30;48;2;102;194;165mfirst\u001b[0m \u001b[0;30;48;2;252;141;98mto\u001b[0m \u001b[0;30;48;2;141;160;203mmake\u001b[0m \u001b[0;30;48;2;231;138;195ma\u001b[0m \u001b[0;30;48;2;166;216;84m[UNK]\u001b[0m \u001b[0;30;48;2;255;217;47mapplication\u001b[0m \u001b[0;30;48;2;102;194;165m.\u001b[0m \u001b[0;30;48;2;252;141;98m[SEP]\u001b[0m \n",
            "Token IDs: [101, 2028, 2097, 2342, 1037, 100, 2034, 2000, 2191, 1037, 100, 4646, 1012, 102]\n",
            "\n",
            "Original text: To ensure features are rotationally insensitive, we order each bin, i ‚àà [1, F], from W+y and W‚àíy, such that S[i] = max {W +yi , W ‚àíyi } and S[i + F] = min {W +yi , W ‚àíyi }\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98mto\u001b[0m \u001b[0;30;48;2;141;160;203mensure\u001b[0m \u001b[0;30;48;2;231;138;195mfeatures\u001b[0m \u001b[0;30;48;2;166;216;84mare\u001b[0m \u001b[0;30;48;2;255;217;47mrotational\u001b[0m \u001b[0;30;48;2;102;194;165m##ly\u001b[0m \u001b[0;30;48;2;252;141;98mins\u001b[0m \u001b[0;30;48;2;141;160;203m##ens\u001b[0m \u001b[0;30;48;2;231;138;195m##itive\u001b[0m \u001b[0;30;48;2;166;216;84m,\u001b[0m \u001b[0;30;48;2;255;217;47mwe\u001b[0m \u001b[0;30;48;2;102;194;165morder\u001b[0m \u001b[0;30;48;2;252;141;98meach\u001b[0m \u001b[0;30;48;2;141;160;203mbin\u001b[0m \u001b[0;30;48;2;231;138;195m,\u001b[0m \u001b[0;30;48;2;166;216;84mi\u001b[0m \u001b[0;30;48;2;255;217;47m‚àà\u001b[0m \u001b[0;30;48;2;102;194;165m[\u001b[0m \u001b[0;30;48;2;252;141;98m1\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mf\u001b[0m \u001b[0;30;48;2;166;216;84m]\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165mfrom\u001b[0m \u001b[0;30;48;2;252;141;98mw\u001b[0m \u001b[0;30;48;2;141;160;203m+\u001b[0m \u001b[0;30;48;2;231;138;195my\u001b[0m \u001b[0;30;48;2;166;216;84mand\u001b[0m \u001b[0;30;48;2;255;217;47mw\u001b[0m \u001b[0;30;48;2;102;194;165m##‚àí\u001b[0m \u001b[0;30;48;2;252;141;98m##y\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195msuch\u001b[0m \u001b[0;30;48;2;166;216;84mthat\u001b[0m \u001b[0;30;48;2;255;217;47ms\u001b[0m \u001b[0;30;48;2;102;194;165m[\u001b[0m \u001b[0;30;48;2;252;141;98mi\u001b[0m \u001b[0;30;48;2;141;160;203m]\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84mmax\u001b[0m \u001b[0;30;48;2;255;217;47m{\u001b[0m \u001b[0;30;48;2;102;194;165mw\u001b[0m \u001b[0;30;48;2;252;141;98m+\u001b[0m \u001b[0;30;48;2;141;160;203myi\u001b[0m \u001b[0;30;48;2;231;138;195m,\u001b[0m \u001b[0;30;48;2;166;216;84mw\u001b[0m \u001b[0;30;48;2;255;217;47m‚àí\u001b[0m \u001b[0;30;48;2;102;194;165m##yi\u001b[0m \u001b[0;30;48;2;252;141;98m}\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195ms\u001b[0m \u001b[0;30;48;2;166;216;84m[\u001b[0m \u001b[0;30;48;2;255;217;47mi\u001b[0m \u001b[0;30;48;2;102;194;165m+\u001b[0m \u001b[0;30;48;2;252;141;98mf\u001b[0m \u001b[0;30;48;2;141;160;203m]\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84mmin\u001b[0m \u001b[0;30;48;2;255;217;47m{\u001b[0m \u001b[0;30;48;2;102;194;165mw\u001b[0m \u001b[0;30;48;2;252;141;98m+\u001b[0m \u001b[0;30;48;2;141;160;203myi\u001b[0m \u001b[0;30;48;2;231;138;195m,\u001b[0m \u001b[0;30;48;2;166;216;84mw\u001b[0m \u001b[0;30;48;2;255;217;47m‚àí\u001b[0m \u001b[0;30;48;2;102;194;165m##yi\u001b[0m \u001b[0;30;48;2;252;141;98m}\u001b[0m \u001b[0;30;48;2;141;160;203m[SEP]\u001b[0m \n",
            "Token IDs: [101, 2000, 5676, 2838, 2024, 25254, 2135, 16021, 6132, 13043, 1010, 2057, 2344, 2169, 8026, 1010, 1045, 1596, 1031, 1015, 1010, 1042, 1033, 1010, 2013, 1059, 1009, 1061, 1998, 1059, 22543, 2100, 1010, 2107, 2008, 1055, 1031, 1045, 1033, 1027, 4098, 1063, 1059, 1009, 12316, 1010, 1059, 1597, 10139, 1065, 1998, 1055, 1031, 1045, 1009, 1042, 1033, 1027, 8117, 1063, 1059, 1009, 12316, 1010, 1059, 1597, 10139, 1065, 102]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenized_prompts = tokenizer_split(\"gpt2\", texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNFuy68LP6bO",
        "outputId": "506c529d-7418-41e9-bcc0-136733c8845a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: New methodologies and prototype systems for dynamically incorporating automatic feature extraction, visual selection, and knowledge-rich semantics for content-based image database management and retrieval are needed to assist image analysts.\n",
            "\u001b[0;30;48;2;102;194;165mNew\u001b[0m \u001b[0;30;48;2;252;141;98m method\u001b[0m \u001b[0;30;48;2;141;160;203mologies\u001b[0m \u001b[0;30;48;2;231;138;195m and\u001b[0m \u001b[0;30;48;2;166;216;84m prototype\u001b[0m \u001b[0;30;48;2;255;217;47m systems\u001b[0m \u001b[0;30;48;2;102;194;165m for\u001b[0m \u001b[0;30;48;2;252;141;98m dynamically\u001b[0m \u001b[0;30;48;2;141;160;203m incorporating\u001b[0m \u001b[0;30;48;2;231;138;195m automatic\u001b[0m \u001b[0;30;48;2;166;216;84m feature\u001b[0m \u001b[0;30;48;2;255;217;47m extraction\u001b[0m \u001b[0;30;48;2;102;194;165m,\u001b[0m \u001b[0;30;48;2;252;141;98m visual\u001b[0m \u001b[0;30;48;2;141;160;203m selection\u001b[0m \u001b[0;30;48;2;231;138;195m,\u001b[0m \u001b[0;30;48;2;166;216;84m and\u001b[0m \u001b[0;30;48;2;255;217;47m knowledge\u001b[0m \u001b[0;30;48;2;102;194;165m-\u001b[0m \u001b[0;30;48;2;252;141;98mrich\u001b[0m \u001b[0;30;48;2;141;160;203m semantics\u001b[0m \u001b[0;30;48;2;231;138;195m for\u001b[0m \u001b[0;30;48;2;166;216;84m content\u001b[0m \u001b[0;30;48;2;255;217;47m-\u001b[0m \u001b[0;30;48;2;102;194;165mbased\u001b[0m \u001b[0;30;48;2;252;141;98m image\u001b[0m \u001b[0;30;48;2;141;160;203m database\u001b[0m \u001b[0;30;48;2;231;138;195m management\u001b[0m \u001b[0;30;48;2;166;216;84m and\u001b[0m \u001b[0;30;48;2;255;217;47m retrieval\u001b[0m \u001b[0;30;48;2;102;194;165m are\u001b[0m \u001b[0;30;48;2;252;141;98m needed\u001b[0m \u001b[0;30;48;2;141;160;203m to\u001b[0m \u001b[0;30;48;2;231;138;195m assist\u001b[0m \u001b[0;30;48;2;166;216;84m image\u001b[0m \u001b[0;30;48;2;255;217;47m analysts\u001b[0m \u001b[0;30;48;2;102;194;165m.\u001b[0m \n",
            "Token IDs: [3791, 2446, 5823, 290, 14879, 3341, 329, 32366, 29927, 11353, 3895, 22236, 11, 5874, 6356, 11, 290, 3725, 12, 7527, 33815, 329, 2695, 12, 3106, 2939, 6831, 4542, 290, 45069, 389, 2622, 284, 3342, 2939, 13440, 13]\n",
            "\n",
            "Original text: GeoIRIS can be best described by its architecture as shown in Fig. 1. There are six modules: feature extraction (FE), indexing structures (IS), semantic framework (SF), GeoName server (GS), fusion and ranking (FR), and retrieval visualization (RV).\n",
            "\u001b[0;30;48;2;102;194;165mGe\u001b[0m \u001b[0;30;48;2;252;141;98mo\u001b[0m \u001b[0;30;48;2;141;160;203mIR\u001b[0m \u001b[0;30;48;2;231;138;195mIS\u001b[0m \u001b[0;30;48;2;166;216;84m can\u001b[0m \u001b[0;30;48;2;255;217;47m be\u001b[0m \u001b[0;30;48;2;102;194;165m best\u001b[0m \u001b[0;30;48;2;252;141;98m described\u001b[0m \u001b[0;30;48;2;141;160;203m by\u001b[0m \u001b[0;30;48;2;231;138;195m its\u001b[0m \u001b[0;30;48;2;166;216;84m architecture\u001b[0m \u001b[0;30;48;2;255;217;47m as\u001b[0m \u001b[0;30;48;2;102;194;165m shown\u001b[0m \u001b[0;30;48;2;252;141;98m in\u001b[0m \u001b[0;30;48;2;141;160;203m Fig\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m 1\u001b[0m \u001b[0;30;48;2;255;217;47m.\u001b[0m \u001b[0;30;48;2;102;194;165m There\u001b[0m \u001b[0;30;48;2;252;141;98m are\u001b[0m \u001b[0;30;48;2;141;160;203m six\u001b[0m \u001b[0;30;48;2;231;138;195m modules\u001b[0m \u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47m feature\u001b[0m \u001b[0;30;48;2;102;194;165m extraction\u001b[0m \u001b[0;30;48;2;252;141;98m (\u001b[0m \u001b[0;30;48;2;141;160;203mFE\u001b[0m \u001b[0;30;48;2;231;138;195m),\u001b[0m \u001b[0;30;48;2;166;216;84m index\u001b[0m \u001b[0;30;48;2;255;217;47ming\u001b[0m \u001b[0;30;48;2;102;194;165m structures\u001b[0m \u001b[0;30;48;2;252;141;98m (\u001b[0m \u001b[0;30;48;2;141;160;203mIS\u001b[0m \u001b[0;30;48;2;231;138;195m),\u001b[0m \u001b[0;30;48;2;166;216;84m semantic\u001b[0m \u001b[0;30;48;2;255;217;47m framework\u001b[0m \u001b[0;30;48;2;102;194;165m (\u001b[0m \u001b[0;30;48;2;252;141;98mSF\u001b[0m \u001b[0;30;48;2;141;160;203m),\u001b[0m \u001b[0;30;48;2;231;138;195m Geo\u001b[0m \u001b[0;30;48;2;166;216;84mName\u001b[0m \u001b[0;30;48;2;255;217;47m server\u001b[0m \u001b[0;30;48;2;102;194;165m (\u001b[0m \u001b[0;30;48;2;252;141;98mGS\u001b[0m \u001b[0;30;48;2;141;160;203m),\u001b[0m \u001b[0;30;48;2;231;138;195m fusion\u001b[0m \u001b[0;30;48;2;166;216;84m and\u001b[0m \u001b[0;30;48;2;255;217;47m ranking\u001b[0m \u001b[0;30;48;2;102;194;165m (\u001b[0m \u001b[0;30;48;2;252;141;98mFR\u001b[0m \u001b[0;30;48;2;141;160;203m),\u001b[0m \u001b[0;30;48;2;231;138;195m and\u001b[0m \u001b[0;30;48;2;166;216;84m retrieval\u001b[0m \u001b[0;30;48;2;255;217;47m visualization\u001b[0m \u001b[0;30;48;2;102;194;165m (\u001b[0m \u001b[0;30;48;2;252;141;98mR\u001b[0m \u001b[0;30;48;2;141;160;203mV\u001b[0m \u001b[0;30;48;2;231;138;195m).\u001b[0m \n",
            "Token IDs: [10082, 78, 4663, 1797, 460, 307, 1266, 3417, 416, 663, 10959, 355, 3402, 287, 12138, 13, 352, 13, 1318, 389, 2237, 13103, 25, 3895, 22236, 357, 15112, 828, 6376, 278, 8573, 357, 1797, 828, 37865, 9355, 357, 20802, 828, 32960, 5376, 4382, 357, 14313, 828, 21748, 290, 12759, 357, 10913, 828, 290, 45069, 32704, 357, 49, 53, 737]\n",
            "\n",
            "Original text: If I get one more L I'm gonna yeet my controller out a window no cap\n",
            "\u001b[0;30;48;2;102;194;165mIf\u001b[0m \u001b[0;30;48;2;252;141;98m I\u001b[0m \u001b[0;30;48;2;141;160;203m get\u001b[0m \u001b[0;30;48;2;231;138;195m one\u001b[0m \u001b[0;30;48;2;166;216;84m more\u001b[0m \u001b[0;30;48;2;255;217;47m L\u001b[0m \u001b[0;30;48;2;102;194;165m I\u001b[0m \u001b[0;30;48;2;252;141;98m'm\u001b[0m \u001b[0;30;48;2;141;160;203m gonna\u001b[0m \u001b[0;30;48;2;231;138;195m ye\u001b[0m \u001b[0;30;48;2;166;216;84met\u001b[0m \u001b[0;30;48;2;255;217;47m my\u001b[0m \u001b[0;30;48;2;102;194;165m controller\u001b[0m \u001b[0;30;48;2;252;141;98m out\u001b[0m \u001b[0;30;48;2;141;160;203m a\u001b[0m \u001b[0;30;48;2;231;138;195m window\u001b[0m \u001b[0;30;48;2;166;216;84m no\u001b[0m \u001b[0;30;48;2;255;217;47m cap\u001b[0m \n",
            "Token IDs: [1532, 314, 651, 530, 517, 406, 314, 1101, 8066, 9838, 316, 616, 10444, 503, 257, 4324, 645, 1451]\n",
            "\n",
            "Original text: One will need a üñ•Ô∏è first to make a üåè application.\n",
            "\u001b[0;30;48;2;102;194;165mOne\u001b[0m \u001b[0;30;48;2;252;141;98m will\u001b[0m \u001b[0;30;48;2;141;160;203m need\u001b[0m \u001b[0;30;48;2;231;138;195m a\u001b[0m \u001b[0;30;48;2;166;216;84m ÔøΩ\u001b[0m \u001b[0;30;48;2;255;217;47mÔøΩ\u001b[0m \u001b[0;30;48;2;102;194;165mÔøΩ\u001b[0m \u001b[0;30;48;2;252;141;98mÔ∏è\u001b[0m \u001b[0;30;48;2;141;160;203m first\u001b[0m \u001b[0;30;48;2;231;138;195m to\u001b[0m \u001b[0;30;48;2;166;216;84m make\u001b[0m \u001b[0;30;48;2;255;217;47m a\u001b[0m \u001b[0;30;48;2;102;194;165m ÔøΩ\u001b[0m \u001b[0;30;48;2;252;141;98mÔøΩ\u001b[0m \u001b[0;30;48;2;141;160;203mÔøΩ\u001b[0m \u001b[0;30;48;2;231;138;195m application\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \n",
            "Token IDs: [3198, 481, 761, 257, 12520, 244, 98, 37929, 717, 284, 787, 257, 12520, 234, 237, 3586, 13]\n",
            "\n",
            "Original text: To ensure features are rotationally insensitive, we order each bin, i ‚àà [1, F], from W+y and W‚àíy, such that S[i] = max {W +yi , W ‚àíyi } and S[i + F] = min {W +yi , W ‚àíyi }\n",
            "\u001b[0;30;48;2;102;194;165mTo\u001b[0m \u001b[0;30;48;2;252;141;98m ensure\u001b[0m \u001b[0;30;48;2;141;160;203m features\u001b[0m \u001b[0;30;48;2;231;138;195m are\u001b[0m \u001b[0;30;48;2;166;216;84m rotation\u001b[0m \u001b[0;30;48;2;255;217;47mally\u001b[0m \u001b[0;30;48;2;102;194;165m insensitive\u001b[0m \u001b[0;30;48;2;252;141;98m,\u001b[0m \u001b[0;30;48;2;141;160;203m we\u001b[0m \u001b[0;30;48;2;231;138;195m order\u001b[0m \u001b[0;30;48;2;166;216;84m each\u001b[0m \u001b[0;30;48;2;255;217;47m bin\u001b[0m \u001b[0;30;48;2;102;194;165m,\u001b[0m \u001b[0;30;48;2;252;141;98m i\u001b[0m \u001b[0;30;48;2;141;160;203m ÔøΩ\u001b[0m \u001b[0;30;48;2;231;138;195mÔøΩ\u001b[0m \u001b[0;30;48;2;166;216;84m [\u001b[0m \u001b[0;30;48;2;255;217;47m1\u001b[0m \u001b[0;30;48;2;102;194;165m,\u001b[0m \u001b[0;30;48;2;252;141;98m F\u001b[0m \u001b[0;30;48;2;141;160;203m],\u001b[0m \u001b[0;30;48;2;231;138;195m from\u001b[0m \u001b[0;30;48;2;166;216;84m W\u001b[0m \u001b[0;30;48;2;255;217;47m+\u001b[0m \u001b[0;30;48;2;102;194;165my\u001b[0m \u001b[0;30;48;2;252;141;98m and\u001b[0m \u001b[0;30;48;2;141;160;203m W\u001b[0m \u001b[0;30;48;2;231;138;195m‚àí\u001b[0m \u001b[0;30;48;2;166;216;84my\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165m such\u001b[0m \u001b[0;30;48;2;252;141;98m that\u001b[0m \u001b[0;30;48;2;141;160;203m S\u001b[0m \u001b[0;30;48;2;231;138;195m[\u001b[0m \u001b[0;30;48;2;166;216;84mi\u001b[0m \u001b[0;30;48;2;255;217;47m]\u001b[0m \u001b[0;30;48;2;102;194;165m =\u001b[0m \u001b[0;30;48;2;252;141;98m max\u001b[0m \u001b[0;30;48;2;141;160;203m {\u001b[0m \u001b[0;30;48;2;231;138;195mW\u001b[0m \u001b[0;30;48;2;166;216;84m +\u001b[0m \u001b[0;30;48;2;255;217;47myi\u001b[0m \u001b[0;30;48;2;102;194;165m ,\u001b[0m \u001b[0;30;48;2;252;141;98m W\u001b[0m \u001b[0;30;48;2;141;160;203m ‚àí\u001b[0m \u001b[0;30;48;2;231;138;195myi\u001b[0m \u001b[0;30;48;2;166;216;84m }\u001b[0m \u001b[0;30;48;2;255;217;47m and\u001b[0m \u001b[0;30;48;2;102;194;165m S\u001b[0m \u001b[0;30;48;2;252;141;98m[\u001b[0m \u001b[0;30;48;2;141;160;203mi\u001b[0m \u001b[0;30;48;2;231;138;195m +\u001b[0m \u001b[0;30;48;2;166;216;84m F\u001b[0m \u001b[0;30;48;2;255;217;47m]\u001b[0m \u001b[0;30;48;2;102;194;165m =\u001b[0m \u001b[0;30;48;2;252;141;98m min\u001b[0m \u001b[0;30;48;2;141;160;203m {\u001b[0m \u001b[0;30;48;2;231;138;195mW\u001b[0m \u001b[0;30;48;2;166;216;84m +\u001b[0m \u001b[0;30;48;2;255;217;47myi\u001b[0m \u001b[0;30;48;2;102;194;165m ,\u001b[0m \u001b[0;30;48;2;252;141;98m W\u001b[0m \u001b[0;30;48;2;141;160;203m ‚àí\u001b[0m \u001b[0;30;48;2;231;138;195myi\u001b[0m \u001b[0;30;48;2;166;216;84m }\u001b[0m \n",
            "Token IDs: [2514, 4155, 3033, 389, 13179, 453, 41246, 11, 356, 1502, 1123, 9874, 11, 1312, 18872, 230, 685, 16, 11, 376, 4357, 422, 370, 10, 88, 290, 370, 14095, 88, 11, 884, 326, 311, 58, 72, 60, 796, 3509, 1391, 54, 1343, 48111, 837, 370, 9746, 48111, 1782, 290, 311, 58, 72, 1343, 376, 60, 796, 949, 1391, 54, 1343, 48111, 837, 370, 9746, 48111, 1782]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phi3_mini4K_tokenized_prompts = tokenizer_split(\"microsoft/Phi-3-mini-4k-instruct\", texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdxbLwYQP9Da",
        "outputId": "322796b3-20f4-4e2b-bd18-2a607cd3979f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: New methodologies and prototype systems for dynamically incorporating automatic feature extraction, visual selection, and knowledge-rich semantics for content-based image database management and retrieval are needed to assist image analysts.\n",
            "\u001b[0;30;48;2;102;194;165mNew\u001b[0m \u001b[0;30;48;2;252;141;98mmethod\u001b[0m \u001b[0;30;48;2;141;160;203mologies\u001b[0m \u001b[0;30;48;2;231;138;195mand\u001b[0m \u001b[0;30;48;2;166;216;84mprototype\u001b[0m \u001b[0;30;48;2;255;217;47msystems\u001b[0m \u001b[0;30;48;2;102;194;165mfor\u001b[0m \u001b[0;30;48;2;252;141;98mdynamically\u001b[0m \u001b[0;30;48;2;141;160;203mincorpor\u001b[0m \u001b[0;30;48;2;231;138;195mating\u001b[0m \u001b[0;30;48;2;166;216;84mautomatic\u001b[0m \u001b[0;30;48;2;255;217;47mfeature\u001b[0m \u001b[0;30;48;2;102;194;165mextra\u001b[0m \u001b[0;30;48;2;252;141;98mction\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mvisual\u001b[0m \u001b[0;30;48;2;166;216;84mselection\u001b[0m \u001b[0;30;48;2;255;217;47m,\u001b[0m \u001b[0;30;48;2;102;194;165mand\u001b[0m \u001b[0;30;48;2;252;141;98mknowledge\u001b[0m \u001b[0;30;48;2;141;160;203m-\u001b[0m \u001b[0;30;48;2;231;138;195mrich\u001b[0m \u001b[0;30;48;2;166;216;84msemantics\u001b[0m \u001b[0;30;48;2;255;217;47mfor\u001b[0m \u001b[0;30;48;2;102;194;165mcontent\u001b[0m \u001b[0;30;48;2;252;141;98m-\u001b[0m \u001b[0;30;48;2;141;160;203mbased\u001b[0m \u001b[0;30;48;2;231;138;195mimage\u001b[0m \u001b[0;30;48;2;166;216;84mdatabase\u001b[0m \u001b[0;30;48;2;255;217;47mmanagement\u001b[0m \u001b[0;30;48;2;102;194;165mand\u001b[0m \u001b[0;30;48;2;252;141;98mretr\u001b[0m \u001b[0;30;48;2;141;160;203mieval\u001b[0m \u001b[0;30;48;2;231;138;195mare\u001b[0m \u001b[0;30;48;2;166;216;84mneeded\u001b[0m \u001b[0;30;48;2;255;217;47mto\u001b[0m \u001b[0;30;48;2;102;194;165massist\u001b[0m \u001b[0;30;48;2;252;141;98mimage\u001b[0m \u001b[0;30;48;2;141;160;203manal\u001b[0m \u001b[0;30;48;2;231;138;195myst\u001b[0m \u001b[0;30;48;2;166;216;84ms\u001b[0m \u001b[0;30;48;2;255;217;47m.\u001b[0m \n",
            "Token IDs: [1570, 1158, 11763, 322, 22267, 6757, 363, 11200, 11039, 1218, 18428, 4682, 4805, 428, 29892, 7604, 9262, 29892, 322, 7134, 29899, 4018, 29505, 363, 2793, 29899, 6707, 1967, 2566, 10643, 322, 5663, 16837, 526, 4312, 304, 6985, 1967, 3483, 858, 29879, 29889]\n",
            "\n",
            "Original text: GeoIRIS can be best described by its architecture as shown in Fig. 1. There are six modules: feature extraction (FE), indexing structures (IS), semantic framework (SF), GeoName server (GS), fusion and ranking (FR), and retrieval visualization (RV).\n",
            "\u001b[0;30;48;2;102;194;165mGe\u001b[0m \u001b[0;30;48;2;252;141;98mo\u001b[0m \u001b[0;30;48;2;141;160;203mIR\u001b[0m \u001b[0;30;48;2;231;138;195mIS\u001b[0m \u001b[0;30;48;2;166;216;84mcan\u001b[0m \u001b[0;30;48;2;255;217;47mbe\u001b[0m \u001b[0;30;48;2;102;194;165mbest\u001b[0m \u001b[0;30;48;2;252;141;98mdescribed\u001b[0m \u001b[0;30;48;2;141;160;203mby\u001b[0m \u001b[0;30;48;2;231;138;195mits\u001b[0m \u001b[0;30;48;2;166;216;84marchitecture\u001b[0m \u001b[0;30;48;2;255;217;47mas\u001b[0m \u001b[0;30;48;2;102;194;165mshown\u001b[0m \u001b[0;30;48;2;252;141;98min\u001b[0m \u001b[0;30;48;2;141;160;203mFig\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m\u001b[0m \u001b[0;30;48;2;255;217;47m1\u001b[0m \u001b[0;30;48;2;102;194;165m.\u001b[0m \u001b[0;30;48;2;252;141;98mThere\u001b[0m \u001b[0;30;48;2;141;160;203mare\u001b[0m \u001b[0;30;48;2;231;138;195msix\u001b[0m \u001b[0;30;48;2;166;216;84mmodules\u001b[0m \u001b[0;30;48;2;255;217;47m:\u001b[0m \u001b[0;30;48;2;102;194;165mfeature\u001b[0m \u001b[0;30;48;2;252;141;98mextra\u001b[0m \u001b[0;30;48;2;141;160;203mction\u001b[0m \u001b[0;30;48;2;231;138;195m(\u001b[0m \u001b[0;30;48;2;166;216;84mFE\u001b[0m \u001b[0;30;48;2;255;217;47m),\u001b[0m \u001b[0;30;48;2;102;194;165mindexing\u001b[0m \u001b[0;30;48;2;252;141;98mstructures\u001b[0m \u001b[0;30;48;2;141;160;203m(\u001b[0m \u001b[0;30;48;2;231;138;195mIS\u001b[0m \u001b[0;30;48;2;166;216;84m),\u001b[0m \u001b[0;30;48;2;255;217;47msemantic\u001b[0m \u001b[0;30;48;2;102;194;165mframework\u001b[0m \u001b[0;30;48;2;252;141;98m(\u001b[0m \u001b[0;30;48;2;141;160;203mSF\u001b[0m \u001b[0;30;48;2;231;138;195m),\u001b[0m \u001b[0;30;48;2;166;216;84mGe\u001b[0m \u001b[0;30;48;2;255;217;47mo\u001b[0m \u001b[0;30;48;2;102;194;165mName\u001b[0m \u001b[0;30;48;2;252;141;98mserver\u001b[0m \u001b[0;30;48;2;141;160;203m(\u001b[0m \u001b[0;30;48;2;231;138;195mGS\u001b[0m \u001b[0;30;48;2;166;216;84m),\u001b[0m \u001b[0;30;48;2;255;217;47mfusion\u001b[0m \u001b[0;30;48;2;102;194;165mand\u001b[0m \u001b[0;30;48;2;252;141;98mranking\u001b[0m \u001b[0;30;48;2;141;160;203m(\u001b[0m \u001b[0;30;48;2;231;138;195mFR\u001b[0m \u001b[0;30;48;2;166;216;84m),\u001b[0m \u001b[0;30;48;2;255;217;47mand\u001b[0m \u001b[0;30;48;2;102;194;165mretr\u001b[0m \u001b[0;30;48;2;252;141;98mieval\u001b[0m \u001b[0;30;48;2;141;160;203mvisual\u001b[0m \u001b[0;30;48;2;231;138;195mization\u001b[0m \u001b[0;30;48;2;166;216;84m(\u001b[0m \u001b[0;30;48;2;255;217;47mR\u001b[0m \u001b[0;30;48;2;102;194;165mV\u001b[0m \u001b[0;30;48;2;252;141;98m).\u001b[0m \n",
            "Token IDs: [1879, 29877, 8193, 3235, 508, 367, 1900, 5439, 491, 967, 11258, 408, 4318, 297, 5104, 29889, 29871, 29896, 29889, 1670, 526, 4832, 10585, 29901, 4682, 4805, 428, 313, 16359, 511, 26190, 12286, 313, 3235, 511, 28837, 6890, 313, 20322, 511, 1879, 29877, 1170, 1923, 313, 10749, 511, 21736, 322, 24034, 313, 15860, 511, 322, 5663, 16837, 7604, 2133, 313, 29934, 29963, 467]\n",
            "\n",
            "Original text: If I get one more L I'm gonna yeet my controller out a window no cap\n",
            "\u001b[0;30;48;2;102;194;165mIf\u001b[0m \u001b[0;30;48;2;252;141;98mI\u001b[0m \u001b[0;30;48;2;141;160;203mget\u001b[0m \u001b[0;30;48;2;231;138;195mone\u001b[0m \u001b[0;30;48;2;166;216;84mmore\u001b[0m \u001b[0;30;48;2;255;217;47mL\u001b[0m \u001b[0;30;48;2;102;194;165mI\u001b[0m \u001b[0;30;48;2;252;141;98m'\u001b[0m \u001b[0;30;48;2;141;160;203mm\u001b[0m \u001b[0;30;48;2;231;138;195mg\u001b[0m \u001b[0;30;48;2;166;216;84monna\u001b[0m \u001b[0;30;48;2;255;217;47mye\u001b[0m \u001b[0;30;48;2;102;194;165met\u001b[0m \u001b[0;30;48;2;252;141;98mmy\u001b[0m \u001b[0;30;48;2;141;160;203mcontroller\u001b[0m \u001b[0;30;48;2;231;138;195mout\u001b[0m \u001b[0;30;48;2;166;216;84ma\u001b[0m \u001b[0;30;48;2;255;217;47mwindow\u001b[0m \u001b[0;30;48;2;102;194;165mno\u001b[0m \u001b[0;30;48;2;252;141;98mcap\u001b[0m \n",
            "Token IDs: [960, 306, 679, 697, 901, 365, 306, 29915, 29885, 330, 11586, 8007, 300, 590, 4701, 714, 263, 3474, 694, 2117]\n",
            "\n",
            "Original text: One will need a üñ•Ô∏è first to make a üåè application.\n",
            "\u001b[0;30;48;2;102;194;165mOne\u001b[0m \u001b[0;30;48;2;252;141;98mwill\u001b[0m \u001b[0;30;48;2;141;160;203mneed\u001b[0m \u001b[0;30;48;2;231;138;195ma\u001b[0m \u001b[0;30;48;2;166;216;84m\u001b[0m \u001b[0;30;48;2;255;217;47mÔøΩ\u001b[0m \u001b[0;30;48;2;102;194;165mÔøΩ\u001b[0m \u001b[0;30;48;2;252;141;98mÔøΩ\u001b[0m \u001b[0;30;48;2;141;160;203mÔøΩ\u001b[0m \u001b[0;30;48;2;231;138;195mÔ∏è\u001b[0m \u001b[0;30;48;2;166;216;84mfirst\u001b[0m \u001b[0;30;48;2;255;217;47mto\u001b[0m \u001b[0;30;48;2;102;194;165mmake\u001b[0m \u001b[0;30;48;2;252;141;98ma\u001b[0m \u001b[0;30;48;2;141;160;203m\u001b[0m \u001b[0;30;48;2;231;138;195mÔøΩ\u001b[0m \u001b[0;30;48;2;166;216;84mÔøΩ\u001b[0m \u001b[0;30;48;2;255;217;47mÔøΩ\u001b[0m \u001b[0;30;48;2;102;194;165mÔøΩ\u001b[0m \u001b[0;30;48;2;252;141;98mapplication\u001b[0m \u001b[0;30;48;2;141;160;203m.\u001b[0m \n",
            "Token IDs: [3118, 674, 817, 263, 29871, 243, 162, 153, 168, 30598, 937, 304, 1207, 263, 29871, 243, 162, 143, 146, 2280, 29889]\n",
            "\n",
            "Original text: To ensure features are rotationally insensitive, we order each bin, i ‚àà [1, F], from W+y and W‚àíy, such that S[i] = max {W +yi , W ‚àíyi } and S[i + F] = min {W +yi , W ‚àíyi }\n",
            "\u001b[0;30;48;2;102;194;165mTo\u001b[0m \u001b[0;30;48;2;252;141;98mensure\u001b[0m \u001b[0;30;48;2;141;160;203mfeatures\u001b[0m \u001b[0;30;48;2;231;138;195mare\u001b[0m \u001b[0;30;48;2;166;216;84mrotation\u001b[0m \u001b[0;30;48;2;255;217;47mally\u001b[0m \u001b[0;30;48;2;102;194;165mins\u001b[0m \u001b[0;30;48;2;252;141;98mens\u001b[0m \u001b[0;30;48;2;141;160;203mitive\u001b[0m \u001b[0;30;48;2;231;138;195m,\u001b[0m \u001b[0;30;48;2;166;216;84mwe\u001b[0m \u001b[0;30;48;2;255;217;47morder\u001b[0m \u001b[0;30;48;2;102;194;165meach\u001b[0m \u001b[0;30;48;2;252;141;98mbin\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mi\u001b[0m \u001b[0;30;48;2;166;216;84m\u001b[0m \u001b[0;30;48;2;255;217;47m‚àà\u001b[0m \u001b[0;30;48;2;102;194;165m[\u001b[0m \u001b[0;30;48;2;252;141;98m1\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mF\u001b[0m \u001b[0;30;48;2;166;216;84m],\u001b[0m \u001b[0;30;48;2;255;217;47mfrom\u001b[0m \u001b[0;30;48;2;102;194;165mW\u001b[0m \u001b[0;30;48;2;252;141;98m+\u001b[0m \u001b[0;30;48;2;141;160;203my\u001b[0m \u001b[0;30;48;2;231;138;195mand\u001b[0m \u001b[0;30;48;2;166;216;84mW\u001b[0m \u001b[0;30;48;2;255;217;47m‚àí\u001b[0m \u001b[0;30;48;2;102;194;165my\u001b[0m \u001b[0;30;48;2;252;141;98m,\u001b[0m \u001b[0;30;48;2;141;160;203msuch\u001b[0m \u001b[0;30;48;2;231;138;195mthat\u001b[0m \u001b[0;30;48;2;166;216;84mS\u001b[0m \u001b[0;30;48;2;255;217;47m[\u001b[0m \u001b[0;30;48;2;102;194;165mi\u001b[0m \u001b[0;30;48;2;252;141;98m]\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195mmax\u001b[0m \u001b[0;30;48;2;166;216;84m{\u001b[0m \u001b[0;30;48;2;255;217;47mW\u001b[0m \u001b[0;30;48;2;102;194;165m+\u001b[0m \u001b[0;30;48;2;252;141;98myi\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mW\u001b[0m \u001b[0;30;48;2;166;216;84m‚àí\u001b[0m \u001b[0;30;48;2;255;217;47myi\u001b[0m \u001b[0;30;48;2;102;194;165m}\u001b[0m \u001b[0;30;48;2;252;141;98mand\u001b[0m \u001b[0;30;48;2;141;160;203mS\u001b[0m \u001b[0;30;48;2;231;138;195m[\u001b[0m \u001b[0;30;48;2;166;216;84mi\u001b[0m \u001b[0;30;48;2;255;217;47m+\u001b[0m \u001b[0;30;48;2;102;194;165mF\u001b[0m \u001b[0;30;48;2;252;141;98m]\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195mmin\u001b[0m \u001b[0;30;48;2;166;216;84m{\u001b[0m \u001b[0;30;48;2;255;217;47mW\u001b[0m \u001b[0;30;48;2;102;194;165m+\u001b[0m \u001b[0;30;48;2;252;141;98myi\u001b[0m \u001b[0;30;48;2;141;160;203m,\u001b[0m \u001b[0;30;48;2;231;138;195mW\u001b[0m \u001b[0;30;48;2;166;216;84m‚àí\u001b[0m \u001b[0;30;48;2;255;217;47myi\u001b[0m \u001b[0;30;48;2;102;194;165m}\u001b[0m \n",
            "Token IDs: [1763, 9801, 5680, 526, 13733, 635, 1663, 575, 3321, 29892, 591, 1797, 1269, 9016, 29892, 474, 29871, 30264, 518, 29896, 29892, 383, 1402, 515, 399, 29974, 29891, 322, 399, 30120, 29891, 29892, 1316, 393, 317, 29961, 29875, 29962, 353, 4236, 426, 29956, 718, 25675, 1919, 399, 13935, 25675, 500, 322, 317, 29961, 29875, 718, 383, 29962, 353, 1375, 426, 29956, 718, 25675, 1919, 399, 13935, 25675, 500]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Cross-Tokenizer Comparison**\n",
        "\n",
        "## Tokenization scheme more robuts to slang, emojis, code\n",
        "\n",
        "Phi-3-mini-4k-instruct is more robust for emojis and math symbols because it had the ability of understanding emojis as well as the math symbol ‚àà\n",
        "\n",
        "## Tokenization scheme that produced longest/shortest sequences\n",
        "GPT2 produced the shortest sequence overall & Phi-3-mini-4k-instruct produced the longest sequence overall. This might be because GPT2 is least aggressive in its word splits and Phi-3-mini-4k-instruct is the most aggressive in word-splits"
      ],
      "metadata": {
        "id": "hXLyI_bpek2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_variables(name, tokenized_prompts, emoji_split, unk_token):\n",
        "    total_tokens = 0\n",
        "    total_unk = 0\n",
        "    for prompt in tokenized_prompts:\n",
        "        total_tokens += len(prompt)\n",
        "        total_unk += prompt.count(unk_token)\n",
        "\n",
        "    row = {\"Tokenizer name\": name, \"# of tokens\": total_tokens,\n",
        "           \"emoji split\": emoji_split, \"Unknown tokens count\": total_unk}\n",
        "    return row"
      ],
      "metadata": {
        "id": "qIM6cdEUb0Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row1 = calculate_variables(\"BERT uncased\", bert_tokenized_prompts, \"[UNK]\", 100)\n",
        "row2 = calculate_variables(\"GPT2\", gpt2_tokenized_prompts, \" ÔøΩ ÔøΩ ÔøΩ\", 50256)\n",
        "row3 = calculate_variables(\"Phi-3-mini-4k-instruct\", phi3_mini4K_tokenized_prompts, \"ÔøΩ ÔøΩ ÔøΩ ÔøΩ\",32000)\n",
        "comparison_dataframe = pandas.DataFrame([row1, row2, row3])\n",
        "display(comparison_dataframe)"
      ],
      "metadata": {
        "id": "Z9visugnQTc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "32460147-0e5a-4992-f4cd-875745506555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Tokenizer name  # of tokens emoji split  Unknown tokens count\n",
              "0            BERT uncased          209       [UNK]                     2\n",
              "1                    GPT2          195       ÔøΩ ÔøΩ ÔøΩ                     0\n",
              "2  Phi-3-mini-4k-instruct          212     ÔøΩ ÔøΩ ÔøΩ ÔøΩ                     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-649250dd-1235-4be0-8efc-0e326f79d147\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenizer name</th>\n",
              "      <th># of tokens</th>\n",
              "      <th>emoji split</th>\n",
              "      <th>Unknown tokens count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERT uncased</td>\n",
              "      <td>209</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GPT2</td>\n",
              "      <td>195</td>\n",
              "      <td>ÔøΩ ÔøΩ ÔøΩ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phi-3-mini-4k-instruct</td>\n",
              "      <td>212</td>\n",
              "      <td>ÔøΩ ÔøΩ ÔøΩ ÔøΩ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-649250dd-1235-4be0-8efc-0e326f79d147')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-649250dd-1235-4be0-8efc-0e326f79d147 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-649250dd-1235-4be0-8efc-0e326f79d147');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df710f24-bdcc-4c46-b9ce-649c2cfaf6d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df710f24-bdcc-4c46-b9ce-649c2cfaf6d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df710f24-bdcc-4c46-b9ce-649c2cfaf6d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_48291931-ff5a-4ec8-9cd0-7553fe3bd337\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_dataframe')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_48291931-ff5a-4ec8-9cd0-7553fe3bd337 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_dataframe');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_dataframe",
              "summary": "{\n  \"name\": \"comparison_dataframe\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Tokenizer name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BERT uncased\",\n          \"GPT2\",\n          \"Phi-3-mini-4k-instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"# of tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 195,\n        \"max\": 212,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          209,\n          195,\n          212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emoji split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[UNK]\",\n          \" \\ufffd \\ufffd \\ufffd\",\n          \"\\ufffd \\ufffd \\ufffd \\ufffd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown tokens count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Token Embedding Visualization**\n",
        "\n",
        "- Pick one sentence and one tokenizer from your previous results.\n",
        "- Use the tokenizer‚Äôs pretrained embedding layer (from its associated model) to produce the embedding vector for each token in the sentence.\n",
        "- Use PCA or t-SNE to project the token embeddings to 2D and create a **scatter plot**:\n",
        "  - Each point should be labeled with the decoded token.\n",
        "  - Color points differently for subwords, whole words, and special tokens.\n",
        "- Comment on the geometry: Do related words/subwords cluster? Are special tokens outliers?"
      ],
      "metadata": {
        "id": "-08EtOHteqZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Phi-3-mini-4k-instruct tokenizer and model\n",
        "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Get all token IDs\n",
        "token_ids = list(range(tokenizer.vocab_size))\n",
        "\n",
        "# Get embeddings from model's embedding layer\n",
        "with torch.no_grad():\n",
        "    embeddings = model.get_input_embeddings()(torch.tensor(token_ids))\n",
        "\n",
        "# Reduce to 2D\n",
        "# Option 1: PCA\n",
        "pca = PCA(n_components=2)\n",
        "emb_2d = pca.fit_transform(embeddings.numpy())\n",
        "\n",
        "# Option 2: t-SNE (uncomment if you want)\n",
        "# tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
        "# emb_2d = tsne.fit_transform(embeddings.numpy())\n",
        "\n",
        "# Decode tokens\n",
        "tokens = [tokenizer.decode([tid]) for tid in token_ids]\n",
        "\n",
        "# Determine token type for coloring\n",
        "colors = []\n",
        "for t in tokens:\n",
        "    if t.startswith(\"<\") and t.endswith(\">\"):\n",
        "        colors.append(\"red\")  # special tokens\n",
        "    elif t.startswith(\"‚ñÅ\"):  # SentencePiece uses '‚ñÅ' for start of words\n",
        "        colors.append(\"green\")  # whole word\n",
        "    else:\n",
        "        colors.append(\"blue\")  # subword\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, (x, y) in enumerate(emb_2d):\n",
        "    plt.scatter(x, y, color=colors[i])\n",
        "    plt.text(x, y, tokens[i], fontsize=6)\n",
        "plt.title(\"Token Embeddings Projected to 2D\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vdxZoU5oQQp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Prompt Engineering & Model Output (2 points)**\n",
        "\n",
        "- Take two tokenized prompts that yielded notably different token splits across tokenizers (e.g. one with code/math and one with informal language).\n",
        "- For each:\n",
        "  - Use two *different* language models (‚Äúmatching‚Äù the tokenizer used) to generate text completions.\n",
        "  - In a short table, report:\n",
        "    - Length (in tokens and characters) of the generated output\n",
        "    - Are any [UNK] tokens, empty outputs, or odd/non-conversational results observed?\n",
        "- *Discuss how the tokenizer choice might affect downstream output quality and efficiency.*\n",
        "\n",
        "BERT - They are efficient for retrieval because they use the least amount of tokens to represent texts compared to other tokenizers, however they can not retrieve unicode & emojis as well. In generation tasks, they are good for classification but may have trouble with capitalization.\n",
        "\n",
        "GPT2 - They are good for retrieval because they can handle unknown words by breaking them down into subwords, and they have some representations for unicode & emojis, but required to search through more tokens. In generation tasks, they are sensitive to spacing.\n",
        "\n",
        "Phi-3-mini-4k-instruct - They are efficient for retrieval because they use the least amount of tokens to represent texts compared to other tokenizers, and they can retrieve unicode & emojis. In generation tasks, they consider capitalization & can have a more global view than WordPiece BERT."
      ],
      "metadata": {
        "id": "qEcwIJ6-e8TH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpe_JVOsQN7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Technical Reflection**\n",
        "\n",
        "## Tokenizer choice affects which types of input a model can \"understand\"\n",
        "\n",
        "BERT uses WordPiece. WordPiece uses [UNK] token to represent unseen emojis, breaks math expressions down by characters, has basic tokenization skills for code syntax, and ignores capitalization in tokenization of proper nouns.\n",
        "\n",
        "GPT2 uses Byte-Pair Encoding (BPE). BPE breaks unseen emojis further down as subunits of their Unicode representations, breaks unseen math expressions down by characters, have a better tokenization of code syntax than WordPiece, and can represent capitalization in tokenization of proper nouns.\n",
        "\n",
        "## Efficiency vs Semantic coverage tradeoffs\n",
        "In some cases, more efficient tokenizers capture less meaning and do not have high semantic coverage for all-purpose use cases while more robust semantic coverage tokenizers capture finer meaning but have higher computational and time costs in training.\n"
      ],
      "metadata": {
        "id": "vg4SMu0KfAnw"
      }
    }
  ]
}