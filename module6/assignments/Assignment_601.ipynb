{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c085ecf",
   "metadata": {},
   "source": [
    "# Assignment: Understanding Transformer LLM Internals and Token-Level Analysis\n",
    "\n",
    "**Background:**  This assignment explores the **internal mechanisms** of transformer-based large language models (LLMs) through hands-on analysis of tokenization, probability distributions, attention mechanisms, and generation strategies. You will investigate how LLMs process and generate text at the token level, examining the mathematical foundations behind their predictions.\n",
    "\n",
    "## Instructions and Point Breakdown\n",
    "\n",
    "### 1. **Model Architecture Analysis and Setup (2 points)**\n",
    "\n",
    "- Load a transformer model using Hugging Face `transformers` library (e.g., Phi-3, GPT-2, or Llama model).\n",
    "- **Questions:**\n",
    "  - Examine the model architecture by printing `model`. What are the key components and their dimensions?\n",
    "  - What is the vocabulary size of your chosen model? How does this compare to the hidden dimension?\n",
    "  - Why do transformer models use layer normalization instead of batch normalization?\n",
    "- **Implementation:** Load the model, tokenizer, and display the architecture summary.\n",
    "\n",
    "### 2. **Tokenization and Vocabulary Investigation (3 points)**\n",
    "\n",
    "- **Deep Dive into Tokenization:**\n",
    "  - Choose 5-7 diverse text samples (include technical terms, different languages, numbers, punctuation combinations).\n",
    "  - For each sample, show the tokenization breakdown: `input → token IDs → decoded tokens`.\n",
    "  - **Questions:**\n",
    "    - How does the tokenizer handle out-of-vocabulary words, numbers, and special characters?\n",
    "    - Why might \"The\" and \"the\" tokenize differently? Test this hypothesis.\n",
    "    - What happens when you tokenize the same word in different contexts?\n",
    "  - **Comparative Analysis:** Compare how your model's tokenizer handles the same text vs. a different tokenizer (e.g., compare word-level vs. subword tokenization).\n",
    "\n",
    "### 3. **Probability Distribution and Next-Token Prediction (2 points)**\n",
    "\n",
    "- **Mathematical Understanding:**\n",
    "  - Take a simple prompt like \"The capital of France is\" and examine the model's logits and probability distributions.\n",
    "  - Extract and analyze the top 10 most probable next tokens with their probabilities.\n",
    "  - **Questions:**\n",
    "    - Why do models use softmax for converting logits to probabilities? What would happen with other normalization methods?\n",
    "    - How does temperature affect the probability distribution? Test with temperatures 0.1, 1.0, and 2.0.\n",
    "    - What's the relationship between the model's confidence (probability mass on top token) and the actual correctness of predictions?\n",
    "  - **Analysis:** Create visualizations showing how probability distributions change with different prompts and temperature settings.\n",
    "\n",
    "### 4. **Generation Strategies and Computational Efficiency (2 points)**\n",
    "\n",
    "- **Performance Analysis:**\n",
    "  - Implement and time text generation with and without key-value caching.\n",
    "  - **Questions:**\n",
    "    - Why does caching provide such dramatic speedup? What is being cached and why?\n",
    "    - How does the computational complexity of attention scale with sequence length?\n",
    "    - What are the memory trade-offs between caching and recomputation?\n",
    "  - **Sampling Methods Investigation:**\n",
    "    - Compare greedy decoding, top-k sampling, and nucleus (top-p) sampling on the same prompt.\n",
    "    - Analyze how different sampling methods affect output diversity and quality.\n",
    "\n",
    "### 5. **Model Behavior and Limitations Analysis (1 point)**\n",
    "\n",
    "- **Critical Thinking Questions:**\n",
    "  - Test the model with deliberately ambiguous or trick questions. How does it handle uncertainty?\n",
    "  - Investigate tokenization artifacts: How might unusual tokenization affect model performance?\n",
    "  - **Philosophical Questions:**\n",
    "    - Does the model \"understand\" language or is it performing sophisticated pattern matching? Support your argument with evidence from your experiments.\n",
    "    - How do the model's internal representations (hidden states) relate to human understanding of language?\n",
    "    - What are the implications of the model's next-token prediction objective for its capabilities and limitations?\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "- **Jupyter Notebook** containing:\n",
    "  - All code implementations and outputs from Sections 1-4\n",
    "  - Clear visualizations of probability distributions and tokenization analysis\n",
    "  - Thoughtful written responses to all critical thinking questions\n",
    "  - Evidence-based arguments supported by experimental results\n",
    "- **Written Analysis:** For each critical question, provide 2-3 paragraphs of analysis supported by your experimental observations.\n",
    "- Use Python libraries: `transformers`, `torch`, `matplotlib`, `numpy`, and `pandas` as needed.\n",
    "\n",
    "## Advanced Extensions (Optional)\n",
    "\n",
    "- **Attention Visualization:** Extract and visualize attention weights for specific examples.\n",
    "- **Layer-wise Analysis:** Examine how representations change through different transformer layers.\n",
    "- **Cross-model Comparison:** Compare the internal behaviors of models with different architectures or sizes.\n",
    "\n",
    "**Grading Rubric:**\n",
    "\n",
    "| Section                              | Points |\n",
    "|:-------------------------------------|:------:|\n",
    "| Architecture analysis & setup        | 2      |\n",
    "| Tokenization investigation           | 3      |\n",
    "| Probability & prediction analysis    | 2      |\n",
    "| Generation & efficiency analysis     | 2      |\n",
    "| Critical thinking & reflection       | 1      |\n",
    "| **Total**                           | **10** |\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "- **Technical Implementation (40%):** Correct and insightful use of the code examples and extensions\n",
    "- **Critical Analysis (40%):** Depth of understanding demonstrated through written responses\n",
    "- **Experimental Evidence (20%):** Quality of supporting evidence and experimental design"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
