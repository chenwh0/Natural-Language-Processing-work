{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06af279a",
   "metadata": {},
   "source": [
    "# Assignment: Advanced Text Classification and Model Interpretability\n",
    "\n",
    "**Background:** This assignment advances your understanding of **text classification** beyond basic sentiment analysis. You will implement multiple approaches to text classification, compare traditional machine learning with modern transformer models, and critically analyze model behavior, interpretability, and real-world deployment considerations. The focus is on **understanding the complete pipeline** from data preprocessing to model interpretation rather than just achieving high accuracy.\n",
    "\n",
    "## Instructions and Point Breakdown\n",
    "\n",
    "### 1. **Multi-Modal Text Classification Setup (2 points)**\n",
    "\n",
    "- Use the provided **Rotten Tomatoes dataset** as your base, but extend it by creating additional classification tasks:\n",
    "  - **Binary sentiment**: Positive/Negative (baseline task)\n",
    "  - **Fine-grained sentiment**: 5-class ordinal classification (1-5 stars equivalent)\n",
    "  - **Aspect-based classification**: Extract and classify mentions of specific movie aspects (acting, plot, cinematography, etc.)\n",
    "\n",
    "- **Implementation Requirements:**\n",
    "  - Load and explore the dataset structure\n",
    "  - Create the multi-class labels through data augmentation or external labeling\n",
    "  - Justify your approach to creating the additional classification tasks\n",
    "\n",
    "- **Questions:**\n",
    "  - Why might fine-grained sentiment be more challenging than binary classification?\n",
    "  - What are the trade-offs between single-task and multi-task learning for these related problems?\n",
    "\n",
    "### 2. **Comparative Algorithm Implementation (3 points)**\n",
    "\n",
    "- Implement **three different approaches** to text classification:\n",
    "  \n",
    "  **Traditional ML Pipeline:**\n",
    "  - TF-IDF or Count Vectorization + Logistic Regression/SVM\n",
    "  - Include proper preprocessing (tokenization, stopword removal, etc.)\n",
    "  \n",
    "  **Embedding-Based Approach:**\n",
    "  - Sentence transformers or pre-trained word embeddings\n",
    "  - Simple neural network classifier on top of embeddings\n",
    "  \n",
    "  **Transformer Fine-tuning:**\n",
    "  - Fine-tune a pre-trained model (BERT, RoBERTa, or similar)\n",
    "  - Use proper train/validation/test splits\n",
    "\n",
    "- **Questions:**\n",
    "  - What are the computational and memory trade-offs between these approaches?\n",
    "  - How does performance scale with dataset size for each method?\n",
    "  - Which approach generalizes better to out-of-distribution data?\n",
    "\n",
    "### 3. **Model Interpretability and Error Analysis (2 points)**\n",
    "\n",
    "- **Interpretability Investigation:**\n",
    "  - For the traditional ML model: Analyze top features/words for each class\n",
    "  - For the transformer model: Extract attention weights and analyze what the model focuses on\n",
    "  - Compare interpretability between approaches\n",
    "\n",
    "- **Systematic Error Analysis:**\n",
    "  - Identify classes of examples where each model fails\n",
    "  - Analyze length bias, domain bias, and linguistic complexity effects\n",
    "  - Create confusion matrices and analyze misclassification patterns\n",
    "\n",
    "- **Critical Questions:**\n",
    "  - Do the models learn semantically meaningful patterns or exploit spurious correlations?\n",
    "  - How do attention patterns relate to human understanding of sentiment indicators?\n",
    "  - What are the implications of model opacity for real-world deployment?\n",
    "\n",
    "### 4. **Robustness and Adversarial Testing (2 points)**\n",
    "\n",
    "- **Robustness Evaluation:**\n",
    "  - Test model performance on adversarial examples (negation handling, sarcasm, etc.)\n",
    "  - Evaluate performance on texts with neutral sentiment or mixed sentiments\n",
    "  - Test cross-domain generalization (if possible, evaluate on different review domains)\n",
    "\n",
    "- **Bias and Fairness Analysis:**\n",
    "  - Investigate potential biases in model predictions\n",
    "  - Test performance across different text lengths and writing styles\n",
    "  - Analyze failure modes and edge cases\n",
    "\n",
    "- **Critical Questions:**\n",
    "  - How do different preprocessing choices affect model robustness?\n",
    "  - What are the ethical implications of deploying sentiment analysis models?\n",
    "  - How would you detect and mitigate bias in a production system?\n",
    "\n",
    "### 5. **Real-World Deployment Considerations (1 point)**\n",
    "\n",
    "- **Technical Reflection:**\n",
    "  - Compare inference speed, memory usage, and scalability of your approaches\n",
    "  - Discuss strategies for handling class imbalance and concept drift\n",
    "  - Propose methods for continuous model monitoring and updating\n",
    "\n",
    "- **Critical Analysis Questions:**\n",
    "  - How would you design a feedback loop to improve model performance over time?\n",
    "  - What are the key considerations for deploying text classification in production?\n",
    "  - How do you balance model complexity with interpretability requirements?\n",
    "  - What metrics beyond accuracy are important for evaluating production ML systems?\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "- **Jupyter Notebook** containing:\n",
    "  - Complete implementation of all three approaches\n",
    "  - Thorough experimental comparison with proper statistical testing\n",
    "  - Visualizations of model interpretability (attention maps, feature importance, etc.)\n",
    "  - Comprehensive error analysis with specific examples\n",
    "  - Written responses to all critical thinking questions (2-3 paragraphs each)\n",
    "\n",
    "- **Technical Implementation:** Use libraries including (not limited) `transformers`, `sentence-transformers`, `sklearn`, `matplotlib`, `seaborn`, and `pandas`\n",
    "\n",
    "- **Experimental Rigor:** Include proper cross-validation, statistical significance testing, and ablation studies where appropriate\n",
    "\n",
    "**Grading Rubric:**\n",
    "\n",
    "| Section                                    | Points |\n",
    "|:-------------------------------------------|:------:|\n",
    "| Multi-modal classification setup           | 2      |\n",
    "| Comparative algorithm implementation       | 3      |\n",
    "| Model interpretability & error analysis   | 2      |\n",
    "| Robustness & adversarial testing          | 2      |\n",
    "| Real-world deployment considerations       | 1      |\n",
    "| **Total**                                 | **10** |\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "- **Technical Implementation (35%):** Quality and correctness of implementations, proper experimental design\n",
    "- **Critical Analysis (40%):** Depth of understanding demonstrated in written responses and experimental insights\n",
    "- **Interpretability & Analysis (25%):** Quality of error analysis, attention visualization, and bias investigation\n",
    "\n",
    "**Learning Objectives:**\n",
    "By completing this assignment, students will understand the full lifecycle of text classification systems, from data preprocessing to production deployment, with emphasis on model interpretability, robustness, and ethical considerations in real-world applications."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
