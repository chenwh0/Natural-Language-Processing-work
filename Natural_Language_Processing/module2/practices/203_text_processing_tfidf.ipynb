{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtWleuve4xSp"
   },
   "source": [
    "## Understanding TfidfVectorizer\n",
    "\n",
    "`TfidfVectorizer` is an advanced feature extraction tool from the scikit-learn library that converts text data into a numerical matrix of TF-IDF features, suitable for use in machine learning models.\n",
    "\n",
    "- **TF (Term Frequency)**: This quantifies the frequency of a term within a single document, giving higher weight to terms that occur more frequently.\n",
    "\n",
    "- **IDF (Inverse Document Frequency)**: This assesses the significance of a term across the entire document corpus. It diminishes the weight of terms that occur very commonly across documents, thereby amplifying the importance of rarer terms. The IDF for a term is calculated by taking the logarithm of the ratio of the total number of documents to the number of documents containing the term.\n",
    "\n",
    "- **TF-IDF**: This metric is the product of TF and IDF, reflecting the term's significance within a particular document relative to the entire collection of documents. A term's TF-IDF score increases with its frequency in a document but is balanced by its commonality across all documents.\n",
    "\n",
    "<font color='Blue'><b>Example:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00oGy2pW45ix"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "docs_ext = ['Columbia, Missouri is known for its vibrant college town atmosphere.',\n",
    "            'The University of Missouri in Columbia is a major research institution.',\n",
    "            \"Columbia's weather can be unpredictable, especially in spring.\",\n",
    "            'Columbia, Columbia, a city so vibrant, so vibrant.',\n",
    "            'The Missouri River, the Missouri River, so scenic, so scenic.']\n",
    "\n",
    "# Initialize the TfidfVectorizer with English stop words to be filtered out\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Remove stop words from each document\n",
    "docs_ext_no_stopwords = [\" \".join(analyzer(doc)) for doc in docs_ext]\n",
    "\n",
    "print(docs_ext_no_stopwords)\n",
    "\n",
    "# Fit the vectorizer to the documents to learn the vocabulary\n",
    "vectorizer.fit(docs_ext)\n",
    "\n",
    "# Display the size and content of the learned vocabulary\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(\"Vocabulary content:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# Transform the documents into a TF-IDF-weighted term-document matrix\n",
    "tfidf_matrix = vectorizer.transform(docs_ext)\n",
    "\n",
    "# Retrieve and display the feature names (vocabulary)\n",
    "print(\"\\nFeature names:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the TF-IDF matrix as a dense array\n",
    "# print(\"\\nTF-IDF matrix:\")\n",
    "# print(tfidf_matrix.toarray())\n",
    "\n",
    "# Convert the TF-IDF matrix into a DataFrame for better readability\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(),\n",
    "                        columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nDataFrame representation of the TF-IDF matrix:\")\n",
    "display(tfidf_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFBJVax6OWch"
   },
   "source": [
    "The numbers in the table represent the **TF-IDF (Term Frequency-Inverse Document Frequency) scores** for various terms across different documents. Here's what they indicate:\n",
    "\n",
    "- **Columns**: Each column header represents a unique term (e.g., 'annual', 'calgary', 'city', etc.).\n",
    "- **Rows**: Each row corresponds to a different document (e.g., Document 0, Document 1, etc.).\n",
    "- **Values**: The numerical values are the TF-IDF scores, which measure how important a term is to a document in a collection. A score of **0** means the term does not appear in the document, while higher scores indicate greater importance.\n",
    "\n",
    "For example, in Document 0, the terms 'annual', 'known', and 'stampede' have a score of **0.549**, suggesting they are significant in that document. Conversely, the term 'city' has a score of **0**, indicating it does not appear in Document 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def compute_tf(documents):\n",
    "    \"\"\"Compute term frequency for each term in each document.\"\"\"\n",
    "    tf_list = []\n",
    "    for doc in documents:\n",
    "        words = doc.split()\n",
    "        total_terms = len(words)\n",
    "        tf = defaultdict(float)\n",
    "        for word in words:\n",
    "            tf[word] += 1\n",
    "        for word in tf:\n",
    "            tf[word] /= total_terms\n",
    "        tf_list.append(tf)\n",
    "    return tf_list\n",
    "\n",
    "def compute_idf(documents, smooth=True):\n",
    "    \"\"\"Compute inverse document frequency for each term.\"\"\"\n",
    "    N = len(documents)\n",
    "    doc_freq = defaultdict(int)\n",
    "    for doc in documents:\n",
    "        unique_terms = set(doc.split())\n",
    "        for term in unique_terms:\n",
    "            doc_freq[term] += 1\n",
    "    idf_dict = {}\n",
    "    for term, df in doc_freq.items():\n",
    "        if smooth:\n",
    "            idf_dict[term] = math.log((1 + N) / (1 + df)) + 1\n",
    "        else:\n",
    "            idf_dict[term] = math.log(N / df) if df != 0 else 0.0\n",
    "    return idf_dict\n",
    "\n",
    "def l2_normalize(vec):\n",
    "    norm = math.sqrt(sum(x**2 for x in vec))\n",
    "    return [x / norm if norm != 0 else 0 for x in vec]\n",
    "\n",
    "def compute_tfidf(documents, smooth=True):\n",
    "    \"\"\"Compute both non-normalized and normalized TF-IDF matrices.\"\"\"\n",
    "    tf_list = compute_tf(documents)\n",
    "    idf = compute_idf(documents, smooth=smooth)\n",
    "    vocab = sorted(idf.keys())\n",
    "    tfidf_matrix = []\n",
    "    tfidf_matrix_norm = []\n",
    "    for tf in tf_list:\n",
    "        tfidf = [tf.get(word, 0) * idf[word] for word in vocab]\n",
    "        tfidf_matrix.append(tfidf)\n",
    "        tfidf_matrix_norm.append(l2_normalize(tfidf))\n",
    "    return vocab, tfidf_matrix, tfidf_matrix_norm\n",
    "\n",
    "# Example usage\n",
    "docs = [\n",
    "    'columbia missouri known vibrant college town atmosphere',\n",
    "    'university missouri columbia major research institution',\n",
    "    'columbia weather unpredictable especially spring',\n",
    "    'columbia columbia city vibrant vibrant',\n",
    "    'missouri river missouri river scenic scenic'\n",
    "]\n",
    "\n",
    "# TF Table\n",
    "tf_list = compute_tf(docs)\n",
    "vocab = sorted(set(word for doc in docs for word in doc.split()))\n",
    "tf_table = []\n",
    "for tf in tf_list:\n",
    "    tf_table.append([tf.get(word, 0) for word in vocab])\n",
    "tf_df = pd.DataFrame(tf_table, columns=vocab)\n",
    "print(\"TF (Term Frequency) Table:\")\n",
    "display(tf_df.round(3))\n",
    "\n",
    "# IDF with smoothing\n",
    "idf_smooth = compute_idf(docs, smooth=True)\n",
    "idf_smooth_df = pd.DataFrame(list(idf_smooth.items()), columns=[\"Term\", \"IDF (Smooth)\"])\n",
    "print(\"\\nIDF (Inverse Document Frequency, smooth=True):\")\n",
    "display(idf_smooth_df.sort_values(\"Term\").reset_index(drop=True))\n",
    "\n",
    "# IDF without smoothing\n",
    "idf_nosmooth = compute_idf(docs, smooth=False)\n",
    "idf_nosmooth_df = pd.DataFrame(list(idf_nosmooth.items()), columns=[\"Term\", \"IDF (No Smoothing)\"])\n",
    "print(\"\\nIDF (Inverse Document Frequency, smooth=False):\")\n",
    "display(idf_nosmooth_df.sort_values(\"Term\").reset_index(drop=True))\n",
    "\n",
    "# TF-IDF Table (with smoothing, non-normalized and normalized)\n",
    "vocab, tfidf_matrix, tfidf_matrix_norm = compute_tfidf(docs, smooth=True)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=vocab)\n",
    "tfidf_df_norm = pd.DataFrame(tfidf_matrix_norm, columns=vocab)\n",
    "print(\"\\nTF-IDF Table (smooth=True, non-normalized):\")\n",
    "display(tfidf_df.round(3))\n",
    "print(\"\\nTF-IDF Table (smooth=True, L2 normalized):\")\n",
    "display(tfidf_df_norm.round(3))\n",
    "\n",
    "# TF-IDF Table (without smoothing, non-normalized and normalized)\n",
    "vocab, tfidf_matrix_nosmooth, tfidf_matrix_nosmooth_norm = compute_tfidf(docs, smooth=False)\n",
    "tfidf_nosmooth_df = pd.DataFrame(tfidf_matrix_nosmooth, columns=vocab)\n",
    "tfidf_nosmooth_df_norm = pd.DataFrame(tfidf_matrix_nosmooth_norm, columns=vocab)\n",
    "print(\"\\nTF-IDF Table (smooth=False, non-normalized):\")\n",
    "display(tfidf_nosmooth_df.round(3))\n",
    "print(\"\\nTF-IDF Table (smooth=False, L2 normalized):\")\n",
    "display(tfidf_nosmooth_df_norm.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o6NfhWUBQzp"
   },
   "source": [
    "## Expanding Bag-of-Words with n-Grams\n",
    "\n",
    "The Bag-of-Words (BoW) model is a simple yet powerful way to represent text data for machine learning. However, it has a significant limitation: it ignores word order. For example, \"it's bad, not good at all\" and \"it's good, not bad at all\" would have identical BoW representations despite their opposite meanings. This is where n-grams come into play.\n",
    "\n",
    "### Capturing Context with n-Grams\n",
    "\n",
    "To capture more context, we can extend the BoW model to consider sequences of words:\n",
    "- **Bigrams**: Pairs of consecutive words.\n",
    "- **Trigrams**: Triplets of consecutive words.\n",
    "- **n-Grams**: Sequences of 'n' consecutive words.\n",
    "\n",
    "\n",
    "### Implementing n-Grams with CountVectorizer\n",
    "\n",
    "The `CountVectorizer` and `TfidfVectorizer` classes in scikit-learn can be configured to use n-grams by setting the `ngram_range` parameter. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\"Columbia, Missouri is known for its vibrant college town atmosphere.\",\n",
    "        \"The University of Missouri in Columbia is a major research institution.\",\n",
    "        \"Columbia's weather can be unpredictable, especially in spring.\"\n",
    "        ]\n",
    "\n",
    "# Unigrams (standard BoW)\n",
    "uni_vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=\"english\")\n",
    "uni_matrix = uni_vectorizer.fit_transform(docs)\n",
    "print(\"Unigram features:\", uni_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Bigrams\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words=\"english\")\n",
    "bi_matrix = bi_vectorizer.fit_transform(docs)\n",
    "print(\"Bigram features:\", bi_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NRco_26BRDz"
   },
   "outputs": [],
   "source": [
    "docs = [\"Columbia, Missouri is known for its vibrant college town atmosphere.\",\n",
    "        \"The University of Missouri in Columbia is a major research institution.\",\n",
    "        \"Columbia's weather can be unpredictable, especially in spring.\"\n",
    "        ]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words = \"english\").fit(docs)\n",
    "# ngram_rangetuple (min_n, max_n), default=(1, 1)\n",
    "print(f\"Vocabulary size: {vectorizer.vocabulary_}\")\n",
    "print(f\"Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "ngram_words = vectorizer.transform(docs)\n",
    "pd.DataFrame(ngram_words.toarray(), columns= vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKMObZ8rBXLB"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words = \"english\").fit(docs)\n",
    "print(f\"Vocabulary size: {vectorizer.vocabulary_}\")\n",
    "print(f\"Vocabulary:\")\n",
    "pprint(vectorizer.get_feature_names_out())\n",
    "\n",
    "ngram_words = vectorizer.transform(docs)\n",
    "pd.DataFrame(ngram_words.toarray(), columns= vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoCR9I4XBeRx"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words = \"english\").fit(docs)\n",
    "print(f\"Vocabulary size: {vectorizer.vocabulary_}\")\n",
    "print(f\"Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "ngram_words = vectorizer.transform(docs)\n",
    "pd.DataFrame(ngram_words.toarray(), columns= vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONqH_cC3CAIy"
   },
   "source": [
    "## Td-idf n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKcPOIIPBr44"
   },
   "outputs": [],
   "source": [
    "docs = [\"Columbia, Missouri is known for its vibrant college town atmosphere.\",\n",
    "        \"The University of Missouri in Columbia is a major research institution.\",\n",
    "        \"Columbia's weather can be unpredictable, especially in spring.\"]\n",
    "vect = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "vect.fit(docs)\n",
    "tfidf_words = vect.transform(docs)\n",
    "df = pd.DataFrame(tfidf_words.toarray(), columns=vect.get_feature_names_out())\n",
    "display(df.round(3))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
