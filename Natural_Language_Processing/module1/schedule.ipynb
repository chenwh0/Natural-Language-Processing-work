{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a4e548",
   "metadata": {},
   "source": [
    "# Module: Introduction to NLP and NLP Pipeline\n",
    "\n",
    "## Module Overview\n",
    "\n",
    "This module introduces students to the fundamentals of Natural Language Processing (NLP) and the essential preprocessing pipeline techniques used in NLP applications. Students will learn both theoretical concepts and practical implementation skills through hands-on exercises and real-world examples.\n",
    "\n",
    "### Module Objectives\n",
    "\n",
    "By the end of this module, students will be able to:\n",
    "\n",
    "1. **Understand NLP Fundamentals**: Grasp core concepts, applications, and challenges in Natural Language Processing\n",
    "2. **Master Text Preprocessing**: Implement essential preprocessing techniques including tokenization, stemming, lemmatization, and POS tagging\n",
    "3. **Build NLP Pipelines**: Design and implement complete text processing workflows using industry-standard libraries\n",
    "4. **Apply OCR Techniques**: Extract and process text from images using Python and Tesseract\n",
    "5. **Web Scraping for NLP**: Collect text data from web sources using BeautifulSoup\n",
    "\n",
    "### Module Components\n",
    "\n",
    "#### Theoretical Foundation\n",
    "- Introduction to Natural Language Processing concepts and applications\n",
    "- Understanding the building blocks of language (phonemes, morphemes, syntax, context)\n",
    "- Overview of NLP tasks and their complexity levels\n",
    "- Challenges in NLP: ambiguity, common knowledge, creativity, and diversity\n",
    "\n",
    "#### Practical Skills\n",
    "- Text preprocessing pipeline development\n",
    "- Tokenization and text normalization techniques\n",
    "- Morphological analysis (stemming and lemmatization)\n",
    "- Part-of-speech tagging and linguistic analysis\n",
    "- Optical Character Recognition (OCR) implementation\n",
    "- Web scraping for text data collection\n",
    "\n",
    "---\n",
    "\n",
    "## Module Content\n",
    "\n",
    "### Lecture Materials\n",
    "- **[Introduction to NLP]** - Core concepts, applications, and challenges in NLP\n",
    "- **[Introduction to NLP (PowerPoint)]** - Interactive presentation version\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "For all practice notebooks, please use the \"NLP\" Container.\n",
    "\n",
    "</div>\n",
    "\n",
    "### Practical Sessions (practices/)\n",
    "- **[Web Scraping with BeautifulSoup](practices/101_webscraping_using_beautifulsoup.ipynb)**\n",
    "  - HTML parsing and data extraction\n",
    "  - Handling different web page structures\n",
    "  - Best practices for ethical web scraping\n",
    "  - Building robust scraping pipelines\n",
    "\n",
    "- **[Text Preprocessing Fundamentals](practices/102_text_preprocessing.ipynb)**\n",
    "  - Text normalization techniques\n",
    "  - Cleaning and standardizing text data\n",
    "  - Handling special characters and encoding issues\n",
    "  - Building preprocessing pipelines\n",
    "  - Performance optimization strategies\n",
    "\n",
    "- **[Text Extraction from Images](practices/103_extracting_text_from_images_tesseract.ipynb)**\n",
    "  - Installing and configuring Tesseract OCR\n",
    "  - Image preprocessing for better OCR accuracy\n",
    "  - Custom OCR configuration and optimization\n",
    "  - Multilingual text recognition\n",
    "  - Error correction and postprocessing\n",
    "\n",
    "- **[Tokenization, Stemming, and Lemmatization](practices/104_tokenization_stemming_lemmatization_stopword_postagging.ipynb)**\n",
    "  - Comprehensive tokenization strategies\n",
    "  - Stopword management and custom filtering\n",
    "  - Stemming algorithms comparison and analysis\n",
    "  - Advanced lemmatization with POS tagging\n",
    "  - Performance comparison between NLTK and spaCy\n",
    "  - Building complete preprocessing pipelines\n",
    "\n",
    "---\n",
    "\n",
    "## Assignments\n",
    "\n",
    "### Assignment 1: Intermediate Web Scraping with BeautifulSoup and Data Analysis\n",
    "**File:** [Assignment_101.ipynb](assignments/Assignment_101.ipynb)  \n",
    "**Points:** 10  \n",
    "**Focus:** Web scraping, data cleaning, and basic analysis\n",
    "\n",
    "### Assignment 2: NLP Text Preprocessing\n",
    "**File:** [Assignment_102.ipynb](assignments/Assignment_102.ipynb)  \n",
    "**Points:** 10  \n",
    "**Focus:** Text preprocessing pipeline comparison between NLTK and spaCy\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "### Beginner Level\n",
    "1. Start with **Introduction to NLP** slides to understand core concepts\n",
    "2. Practice **Web Scraping** to learn data collection techniques\n",
    "3. Work through **Text Preprocessing** for foundational skills\n",
    "\n",
    "### Intermediate Level\n",
    "4. Explore **OCR Techniques** for working with image-based text\n",
    "5. Master **Tokenization and Morphological Analysis** for advanced preprocessing\n",
    "\n",
    "### Advanced Level\n",
    "6. Integrate all techniques into comprehensive NLP pipelines\n",
    "7. Optimize for production-level performance and scalability\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Technical Requirements\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with JupyterLab, data structures and file handling\n",
    "\n",
    "### Libraries to Install (Only applicable to your local machines\n",
    "\n",
    "```python\n",
    "# Core NLP libraries\n",
    "pip install nltk spacy\n",
    "\n",
    "# Web scraping\n",
    "pip install beautifulsoup4 requests\n",
    "\n",
    "# OCR and image processing\n",
    "pip install pytesseract pillow opencv-python\n",
    "\n",
    "# Data analysis and visualization\n",
    "pip install pandas matplotlib numpy\n",
    "\n",
    "# Download language models\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d138d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Recommended Background\n",
    "- Basic programming experience in Python\n",
    "- Understanding of regular expressions (helpful but not required)\n",
    "- Familiarity with HTML structure (for web scraping module)\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "### Documentation and References\n",
    "- [NLTK Documentation](https://www.nltk.org/)\n",
    "- [spaCy Documentation](https://spacy.io/)\n",
    "- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Tesseract OCR Documentation](https://tesseract-ocr.github.io/)\n",
    "\n",
    "### Recommended Reading\n",
    "- Vajjala, Sowmya, et al. *Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems*. O'Reilly Media, 2020.\n",
    "- Bird, Steven, Ewan Klein, and Edward Loper. *Natural Language Processing with Python*. O'Reilly Media, 2009.\n",
    "\n",
    "### Online Resources\n",
    "- [Practical NLP Website](https://www.practicalnlp.ai/)\n",
    "- [spaCy Course](https://course.spacy.io/)\n",
    "- [NLTK Book Online](https://www.nltk.org/book/)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. **Clone or Download** the module materials\n",
    "2. **Set up your environment** with the required libraries\n",
    "3. **Start with the slides** in the `slides/` folder for theoretical foundation\n",
    "4. **Work through the notebooks** in the `practices/` folder in order\n",
    "5. **Complete the exercises** and experiment with your own data\n",
    "6. **Build your capstone project** using the learned techniques\n",
    "\n",
    "### Support and Questions\n",
    "- Review the comprehensive examples and explanations in each notebook\n",
    "- Refer to the documentation links for detailed API references\n",
    "- Practice with different datasets to reinforce learning\n",
    "- Experiment with parameter tuning and optimization techniques"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
